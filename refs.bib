
@article{mcinnes_hdbscan_2017,
	title = {hdbscan: {Hierarchical} density based clustering},
	volume = {2},
	issn = {2475-9066},
	shorttitle = {hdbscan},
	url = {https://joss.theoj.org/papers/10.21105/joss.00205},
	doi = {10.21105/joss.00205},
	abstract = {McInnes et al, (2017), hdbscan: Hierarchical density based clustering, Journal of Open Source Software, 2(11), 205, doi:10.21105/joss.00205},
	language = {en},
	number = {11},
	urldate = {2021-09-23},
	journal = {Journal of Open Source Software},
	author = {McInnes, Leland and Healy, John and Astels, Steve},
	month = mar,
	year = {2017},
	pages = {205},
	file = {Full Text PDF:/home/bo/Zotero/storage/VJS8L24K/McInnes et al. - 2017 - hdbscan Hierarchical density based clustering.pdf:application/pdf;Snapshot:/home/bo/Zotero/storage/R2AAG2I2/joss.html:text/html},
}

@article{marshall_continuous_2021,
	title = {Continuous {Whole}-{Body} {3D} {Kinematic} {Recordings} across the {Rodent} {Behavioral} {Repertoire} - {SI}},
	volume = {109},
	issn = {08966273},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627320308941},
	doi = {10.1016/j.neuron.2020.11.016},
	abstract = {In mammalian animal models, high-resolution kinematic tracking is restricted to brief sessions in constrained environments, limiting our ability to probe naturalistic behaviors and their neural underpinnings. To address this, we developed CAPTURE (Continuous Appendicular and Postural Tracking Using Retroreﬂector Embedding), a behavioral monitoring system that combines motion capture and deep learning to continuously track the 3D kinematics of a rat’s head, trunk, and limbs for week-long timescales in freely behaving animals. CAPTURE realizes 10- to 100-fold gains in precision and robustness compared with existing convolutional network approaches to behavioral tracking. We demonstrate CAPTURE’s ability to comprehensively proﬁle the kinematics and sequential organization of natural rodent behavior, its variation across individuals, and its perturbation by drugs and disease, including identifying perseverative grooming states in a rat model of fragile X syndrome. CAPTURE signiﬁcantly expands the range of behaviors and contexts that can be quantitatively investigated, opening the door to a new understanding of natural behavior and its neural basis.},
	language = {en},
	number = {3},
	urldate = {2022-02-19},
	journal = {Neuron},
	author = {Marshall, Jesse D. and Aldarondo, Diego E. and Dunn, Timothy W. and Wang, William L. and Berman, Gordon J. and Ölveczky, Bence P.},
	month = feb,
	year = {2021},
	pages = {420--437.e8},
	file = {Continuous Whole-Body 3D Kinematic Recordings across the Rodent Behavioral Repertoire - SI.pdf:/home/bo/Zotero/storage/TB93FLRG/Continuous Whole-Body 3D Kinematic Recordings across the Rodent Behavioral Repertoire - SI.pdf:application/pdf},
}

@article{berman_mapping_2014,
	title = {Mapping the stereotyped behaviour of freely moving fruit flies},
	volume = {11},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rsif.2014.0672},
	doi = {10.1098/rsif.2014.0672},
	abstract = {A frequent assumption in behavioural science is that most of an animal's activities can be described in terms of a small set of stereotyped motifs. Here, we introduce a method for mapping an animal's actions, relying only upon the underlying structure of postural movement data to organize and classify behaviours. Applying this method to the ground-based behaviour of the fruit fly, Drosophila melanogaster, we find that flies perform stereotyped actions roughly 50\% of the time, discovering over 100 distinguishable, stereotyped behavioural states. These include multiple modes of locomotion and grooming. We use the resulting measurements as the basis for identifying subtle sex-specific behavioural differences and revealing the low-dimensional nature of animal motions.},
	number = {99},
	urldate = {2022-02-20},
	journal = {Journal of The Royal Society Interface},
	author = {Berman, Gordon J. and Choi, Daniel M. and Bialek, William and Shaevitz, Joshua W.},
	month = oct,
	year = {2014},
	note = {Publisher: Royal Society},
	keywords = {behaviour, Drosophila, phase reconstruction, stereotypy, unsupervised learning},
	pages = {20140672},
	file = {Full Text PDF:/home/bo/Zotero/storage/EV3XUS34/Berman et al. - 2014 - Mapping the stereotyped behaviour of freely moving.pdf:application/pdf},
}

@article{marshall_continuous_2021-1,
	title = {Continuous {Whole}-{Body} {3D} {Kinematic} {Recordings} across the {Rodent} {Behavioral} {Repertoire}},
	volume = {109},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627320308941},
	doi = {10.1016/j.neuron.2020.11.016},
	abstract = {In mammalian animal models, high-resolution kinematic tracking is restricted to brief sessions in constrained environments, limiting our ability to probe naturalistic behaviors and their neural underpinnings. To address this, we developed CAPTURE (Continuous Appendicular and Postural Tracking Using Retroreflector Embedding), a behavioral monitoring system that combines motion capture and deep learning to continuously track the 3D kinematics of a rat’s head, trunk, and limbs for week-long timescales in freely behaving animals. CAPTURE realizes 10- to 100-fold gains in precision and robustness compared with existing convolutional network approaches to behavioral tracking. We demonstrate CAPTURE’s ability to comprehensively profile the kinematics and sequential organization of natural rodent behavior, its variation across individuals, and its perturbation by drugs and disease, including identifying perseverative grooming states in a rat model of fragile X syndrome. CAPTURE significantly expands the range of behaviors and contexts that can be quantitatively investigated, opening the door to a new understanding of natural behavior and its neural basis.},
	language = {en},
	number = {3},
	urldate = {2022-02-20},
	journal = {Neuron},
	author = {Marshall, Jesse D. and Aldarondo, Diego E. and Dunn, Timothy W. and Wang, William L. and Berman, Gordon J. and Ölveczky, Bence P.},
	month = feb,
	year = {2021},
	keywords = {animal tracking, autism, behavior, computational ethology, grooming, individuality, motion capture, phenotyping},
	pages = {420--437.e8},
	file = {Full Text:/home/bo/Zotero/storage/DEHFVGAL/Marshall et al. - 2021 - Continuous Whole-Body 3D Kinematic Recordings acro.pdf:application/pdf},
}

@article{mcinnes_umap_2020,
	title = {{UMAP}: {Uniform} {Manifold} {Approximation} and {Projection} for {Dimension} {Reduction}},
	shorttitle = {{UMAP}},
	url = {http://arxiv.org/abs/1802.03426},
	abstract = {UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. e result is a practical scalable algorithm that is applicable to real world data. e UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
	language = {en},
	urldate = {2022-02-21},
	journal = {arXiv:1802.03426 [cs, stat]},
	author = {McInnes, Leland and Healy, John and Melville, James},
	month = sep,
	year = {2020},
	note = {arXiv: 1802.03426},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computational Geometry},
	annote = {Comment: Reference implementation available at http://github.com/lmcinnes/umap},
	file = {McInnes et al. - 2020 - UMAP Uniform Manifold Approximation and Projectio.pdf:/home/bo/Zotero/storage/JVWF8NE2/McInnes et al. - 2020 - UMAP Uniform Manifold Approximation and Projectio.pdf:application/pdf},
}

@inproceedings{campello_density-based_2013,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Density-{Based} {Clustering} {Based} on {Hierarchical} {Density} {Estimates}},
	isbn = {978-3-642-37456-2},
	doi = {10.1007/978-3-642-37456-2_14},
	abstract = {We propose a theoretically and practically improved density-based, hierarchical clustering method, providing a clustering hierarchy from which a simplified tree of significant clusters can be constructed. For obtaining a “flat” partition consisting of only the most significant clusters (possibly corresponding to different density thresholds), we propose a novel cluster stability measure, formalize the problem of maximizing the overall stability of selected clusters, and formulate an algorithm that computes an optimal solution to this problem. We demonstrate that our approach outperforms the current, state-of-the-art, density-based clustering methods on a wide variety of real world data.},
	language = {en},
	booktitle = {Advances in {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Springer},
	author = {Campello, Ricardo J. G. B. and Moulavi, Davoud and Sander, Joerg},
	editor = {Pei, Jian and Tseng, Vincent S. and Cao, Longbing and Motoda, Hiroshi and Xu, Guandong},
	year = {2013},
	keywords = {Cluster Tree, Core Object, Density Threshold, Hierarchical Cluster Method, Minimum Span Tree},
	pages = {160--172},
	file = {Springer Full Text PDF:/home/bo/Zotero/storage/GI8HTQMZ/Campello et al. - 2013 - Density-Based Clustering Based on Hierarchical Den.pdf:application/pdf},
}

@article{katori_103200-arm_2022,
	title = {The 103,200-arm acceleration dataset in the {UK} {Biobank} revealed a landscape of human sleep phenotypes},
	volume = {119},
	url = {https://www.pnas.org/doi/10.1073/pnas.2116729119},
	doi = {10.1073/pnas.2116729119},
	number = {12},
	urldate = {2022-03-29},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Katori, Machiko and Shi, Shoi and Ode, Koji L. and Tomita, Yasuhiro and Ueda, Hiroki R.},
	month = mar,
	year = {2022},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2116729119},
	file = {Full Text PDF:/home/bo/Zotero/storage/EZZN88NH/Katori et al. - 2022 - The 103,200-arm acceleration dataset in the UK Bio.pdf:application/pdf},
}

@article{mathis_deeplabcut_2018,
	title = {{DeepLabCut}: markerless pose estimation of user-defined body parts with deep learning},
	volume = {21},
	copyright = {2018 The Author(s)},
	issn = {1546-1726},
	shorttitle = {{DeepLabCut}},
	url = {https://www.nature.com/articles/s41593-018-0209-y},
	doi = {10.1038/s41593-018-0209-y},
	abstract = {Quantifying behavior is crucial for many applications in neuroscience. Videography provides easy methods for the observation and recording of animal behavior in diverse settings, yet extracting particular aspects of a behavior for further analysis can be highly time consuming. In motor control studies, humans or other animals are often marked with reflective markers to assist with computer-based tracking, but markers are intrusive, and the number and location of the markers must be determined a priori. Here we present an efficient method for markerless pose estimation based on transfer learning with deep neural networks that achieves excellent results with minimal training data. We demonstrate the versatility of this framework by tracking various body parts in multiple species across a broad collection of behaviors. Remarkably, even when only a small number of frames are labeled ({\textasciitilde}200), the algorithm achieves excellent tracking performance on test frames that is comparable to human accuracy.},
	language = {en},
	number = {9},
	urldate = {2022-04-10},
	journal = {Nature Neuroscience},
	author = {Mathis, Alexander and Mamidanna, Pranav and Cury, Kevin M. and Abe, Taiga and Murthy, Venkatesh N. and Mathis, Mackenzie Weygandt and Bethge, Matthias},
	month = sep,
	year = {2018},
	note = {Number: 9
Publisher: Nature Publishing Group},
	keywords = {Behavioural methods, Computational neuroscience, Machine learning},
	pages = {1281--1289},
	file = {Full Text PDF:/home/bo/Zotero/storage/B6HM8ICP/Mathis et al. - 2018 - DeepLabCut markerless pose estimation of user-def.pdf:application/pdf;Snapshot:/home/bo/Zotero/storage/BEMRELFD/s41593-018-0209-y.html:text/html},
}

@article{nath_using_2019,
	title = {Using {DeepLabCut} for {3D} markerless pose estimation across species and behaviors},
	volume = {14},
	issn = {1754-2189, 1750-2799},
	url = {http://www.nature.com/articles/s41596-019-0176-0},
	doi = {10.1038/s41596-019-0176-0},
	language = {en},
	number = {7},
	urldate = {2022-04-10},
	journal = {Nature Protocols},
	author = {Nath, Tanmay and Mathis, Alexander and Chen, An Chi and Patel, Amir and Bethge, Matthias and Mathis, Mackenzie Weygandt},
	month = jul,
	year = {2019},
	pages = {2152--2176},
	file = {Nath et al. - 2019 - Using DeepLabCut for 3D markerless pose estimation.pdf:/home/bo/Zotero/storage/BACB6BDY/Nath et al. - 2019 - Using DeepLabCut for 3D markerless pose estimation.pdf:application/pdf},
}

@article{pereira_fast_2019,
	title = {Fast animal pose estimation using deep neural networks},
	volume = {16},
	copyright = {2018 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-018-0234-5},
	doi = {10.1038/s41592-018-0234-5},
	abstract = {The need for automated and efficient systems for tracking full animal pose has increased with the complexity of behavioral data and analyses. Here we introduce LEAP (LEAP estimates animal pose), a deep-learning-based method for predicting the positions of animal body parts. This framework consists of a graphical interface for labeling of body parts and training the network. LEAP offers fast prediction on new data, and training with as few as 100 frames results in 95\% of peak performance. We validated LEAP using videos of freely behaving fruit flies and tracked 32 distinct points to describe the pose of the head, body, wings and legs, with an error rate of {\textless}3\% of body length. We recapitulated reported findings on insect gait dynamics and demonstrated LEAP’s applicability for unsupervised behavioral classification. Finally, we extended the method to more challenging imaging situations and videos of freely moving mice.},
	language = {en},
	number = {1},
	urldate = {2022-04-12},
	journal = {Nature Methods},
	author = {Pereira, Talmo D. and Aldarondo, Diego E. and Willmore, Lindsay and Kislin, Mikhail and Wang, Samuel S.-H. and Murthy, Mala and Shaevitz, Joshua W.},
	month = jan,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Computational neuroscience, Motor control},
	pages = {117--125},
	file = {Full Text PDF:/home/bo/Zotero/storage/IKBQ4FM8/Pereira et al. - 2019 - Fast animal pose estimation using deep neural netw.pdf:application/pdf},
}

@article{todd_systematic_2017,
	title = {Systematic exploration of unsupervised methods for mapping behavior},
	volume = {14},
	issn = {1478-3975},
	url = {https://doi.org/10.1088/1478-3975/14/1/015002},
	doi = {10.1088/1478-3975/14/1/015002},
	abstract = {To fully understand the mechanisms giving rise to behavior, we need to be able to precisely measure it. When coupled with large behavioral data sets, unsupervised clustering methods offer the potential of unbiased mapping of behavioral spaces. However, unsupervised techniques to map behavioral spaces are in their infancy, and there have been few systematic considerations of all the methodological options. We compared the performance of seven distinct mapping methods in clustering a wavelet-transformed data set consisting of the x- and y-positions of the six legs of individual flies. Legs were automatically tracked by small pieces of fluorescent dye, while the fly was tethered and walking on an air-suspended ball. We find that there is considerable variation in the performance of these mapping methods, and that better performance is attained when clustering is done in higher dimensional spaces (which are otherwise less preferable because they are hard to visualize). High dimensionality means that some algorithms, including the non-parametric watershed cluster assignment algorithm, cannot be used. We developed an alternative watershed algorithm which can be used in high-dimensional spaces when a probability density estimate can be computed directly. With these tools in hand, we examined the behavioral space of fly leg postural dynamics and locomotion. We find a striking division of behavior into modes involving the fore legs and modes involving the hind legs, with few direct transitions between them. By computing behavioral clusters using the data from all flies simultaneously, we show that this division appears to be common to all flies. We also identify individual-to-individual differences in behavior and behavioral transitions. Lastly, we suggest a computational pipeline that can achieve satisfactory levels of performance without the taxing computational demands of a systematic combinatorial approach.},
	language = {en},
	number = {1},
	urldate = {2022-04-22},
	journal = {Physical Biology},
	author = {Todd, Jeremy G. and Kain, Jamey S. and Bivort, Benjamin L. de},
	month = feb,
	year = {2017},
	note = {Publisher: IOP Publishing},
	pages = {015002},
	file = {IOP Full Text PDF:/home/bo/Zotero/storage/2A2CT2TD/Todd et al. - 2017 - Systematic exploration of unsupervised methods for.pdf:application/pdf},
}

@article{lee_pywavelets_2019,
	title = {{PyWavelets}: {A} {Python} package for wavelet analysis},
	volume = {4},
	issn = {2475-9066},
	shorttitle = {{PyWavelets}},
	url = {https://joss.theoj.org/papers/10.21105/joss.01237},
	doi = {10.21105/joss.01237},
	abstract = {Lee et al., (2019). PyWavelets: A Python package for wavelet analysis. Journal of Open Source Software, 4(36), 1237, https://doi.org/10.21105/joss.01237},
	language = {en},
	number = {36},
	urldate = {2022-04-22},
	journal = {Journal of Open Source Software},
	author = {Lee, Gregory R. and Gommers, Ralf and Waselewski, Filip and Wohlfahrt, Kai and O’Leary, Aaron},
	month = apr,
	year = {2019},
	pages = {1237},
	file = {Full Text PDF:/home/bo/Zotero/storage/FNMTKS4Q/Lee et al. - 2019 - PyWavelets A Python package for wavelet analysis.pdf:application/pdf;Snapshot:/home/bo/Zotero/storage/TSS8WE54/joss.html:text/html},
}

@article{liu_rectification_2007,
	title = {Rectification of the {Bias} in the {Wavelet} {Power} {Spectrum}},
	volume = {24},
	issn = {1520-0426, 0739-0572},
	url = {http://journals.ametsoc.org/doi/10.1175/2007JTECHO511.1},
	doi = {10.1175/2007JTECHO511.1},
	abstract = {This paper addresses a bias problem in the estimate of wavelet power spectra for atmospheric and oceanic datasets. For a time series comprised of sine waves with the same amplitude at different frequencies the conventionally adopted wavelet method does not produce a spectrum with identical peaks, in contrast to a Fourier analysis. The wavelet power spectrum in this definition, that is, the transform coefficient squared (to within a constant factor), is equivalent to the integration of energy (in physical space) over the influence period (time scale) the series spans. Thus, a physically consistent definition of energy for the wavelet power spectrum should be the transform coefficient squared divided by the scale it associates. Such adjusted wavelet power spectrum results in a substantial improvement in the spectral estimate, allowing for a comparison of the spectral peaks across scales. The improvement is validated with an artificial time series and a real coastal sea level record. Also examined is the previous example of the wavelet analysis of the Niño-3 SST data.},
	language = {en},
	number = {12},
	urldate = {2022-04-23},
	journal = {Journal of Atmospheric and Oceanic Technology},
	author = {Liu, Yonggang and San Liang, X. and Weisberg, Robert H.},
	month = dec,
	year = {2007},
	pages = {2093--2102},
	file = {Liu et al. - 2007 - Rectification of the Bias in the Wavelet Power Spe.pdf:/home/bo/Zotero/storage/EY8YBCR2/Liu et al. - 2007 - Rectification of the Bias in the Wavelet Power Spe.pdf:application/pdf},
}

@article{kabra_jaaba_2013,
	title = {{JAABA}: interactive machine learning for automatic annotation of animal behavior},
	volume = {10},
	copyright = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1548-7105},
	shorttitle = {{JAABA}},
	url = {https://www.nature.com/articles/nmeth.2281},
	doi = {10.1038/nmeth.2281},
	abstract = {Open-source software that allows biologists to create a variety of behavior classifiers for automatically annotating video of behaving animals is presented. The program, called JAABA, uses state-of-the-art machine-learning methods and is applicable to tracking data from different organisms, including mice and adult and larval Drosophila.},
	language = {en},
	number = {1},
	urldate = {2022-04-23},
	journal = {Nature Methods},
	author = {Kabra, Mayank and Robie, Alice A. and Rivera-Alba, Marta and Branson, Steven and Branson, Kristin},
	month = jan,
	year = {2013},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Behavioural methods, Machine learning, Experimental organisms},
	pages = {64--67},
	file = {Full Text PDF:/home/bo/Zotero/storage/7HQXVSGW/Kabra et al. - 2013 - JAABA interactive machine learning for automatic .pdf:application/pdf;Snapshot:/home/bo/Zotero/storage/Q68HSDHG/nmeth.html:text/html},
}

@article{berman_predictability_2016,
	title = {Predictability and hierarchy in \textit{{Drosophila}} behavior},
	volume = {113},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.1607601113},
	doi = {10.1073/pnas.1607601113},
	abstract = {Significance
            How an animal chooses to order its activities—moving, grooming, resting, and so on—is essential to its ability to survive, adapt, and reproduce. Here we investigate the temporal pattern of behaviors performed by fruit flies, finding that their movements are organized in a hierarchical manner that exhibits long time scales. This organization is likely advantageous for adaptability and ease of neural representation and provides hints as to the form of the fly’s internal representations of behavioral programs.
          , 
            Even the simplest of animals exhibit behavioral sequences with complex temporal dynamics. Prominent among the proposed organizing principles for these dynamics has been the idea of a hierarchy, wherein the movements an animal makes can be understood as a set of nested subclusters. Although this type of organization holds potential advantages in terms of motion control and neural circuitry, measurements demonstrating this for an animal’s entire behavioral repertoire have been limited in scope and temporal complexity. Here, we use a recently developed unsupervised technique to discover and track the occurrence of all stereotyped behaviors performed by fruit flies moving in a shallow arena. Calculating the optimally predictive representation of the fly’s future behaviors, we show that fly behavior exhibits multiple time scales and is organized into a hierarchical structure that is indicative of its underlying behavioral programs and its changing internal states.},
	language = {en},
	number = {42},
	urldate = {2022-04-23},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Berman, Gordon J. and Bialek, William and Shaevitz, Joshua W.},
	month = oct,
	year = {2016},
	pages = {11943--11948},
	file = {Berman et al. - 2016 - Predictability and hierarchy in Drosophila .pdf:/home/bo/Zotero/storage/4WKH8JZ5/Berman et al. - 2016 - Predictability and hierarchy in Drosophila .pdf:application/pdf},
}

@article{pedregosa_scikit-learn_2011,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	volume = {12},
	issn = {1533-7928},
	shorttitle = {Scikit-learn},
	url = {http://jmlr.org/papers/v12/pedregosa11a.html},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	number = {85},
	urldate = {2022-04-23},
	journal = {Journal of Machine Learning Research},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	year = {2011},
	pages = {2825--2830},
	file = {Full Text PDF:/home/bo/Zotero/storage/3CW8S2IZ/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf:application/pdf},
}

@article{torrence_practical_1998,
	title = {A {Practical} {Guide} to {Wavelet} {Analysis}},
	volume = {79},
	issn = {0003-0007, 1520-0477},
	url = {http://journals.ametsoc.org/doi/10.1175/1520-0477(1998)079<0061:APGTWA>2.0.CO;2},
	doi = {10.1175/1520-0477(1998)079<0061:APGTWA>2.0.CO;2},
	abstract = {A practical step-by-step guide to wavelet analysis is given, with examples taken from time series of the El Niño–Southern Oscillation (ENSO). The guide includes a comparison to the windowed Fourier transform, the choice of an appropriate wavelet basis function, edge effects due to finite-length time series, and the relationship between wavelet scale and Fourier frequency. New statistical significance tests for wavelet power spectra are developed by deriving theoretical wavelet spectra for white and red noise processes and using these to establish significance levels and confidence intervals. It is shown that smoothing in time or scale can be used to increase the confidence of the wavelet spectrum. Empirical formulas are given for the effect of smoothing on significance levels and confidence intervals. Extensions to wavelet analysis such as filtering, the power Hovmöller, cross-wavelet spectra, and coherence are described.},
	language = {en},
	number = {1},
	urldate = {2022-04-23},
	journal = {Bulletin of the American Meteorological Society},
	author = {Torrence, Christopher and Compo, Gilbert P.},
	month = jan,
	year = {1998},
	pages = {61--78},
	file = {Torrence and Compo - 1998 - A Practical Guide to Wavelet Analysis.pdf:/home/bo/Zotero/storage/5KK8L35Q/Torrence and Compo - 1998 - A Practical Guide to Wavelet Analysis.pdf:application/pdf},
}

@article{vanderplas_altair_2018,
	title = {Altair: {Interactive} {Statistical} {Visualizations} for {Python}},
	volume = {3},
	issn = {2475-9066},
	shorttitle = {Altair},
	url = {https://joss.theoj.org/papers/10.21105/joss.01057},
	doi = {10.21105/joss.01057},
	abstract = {VanderPlas et al., (2018). Altair: Interactive Statistical Visualizations for Python. Journal of Open Source Software, 3(32), 1057, https://doi.org/10.21105/joss.01057},
	language = {en},
	number = {32},
	urldate = {2022-04-23},
	journal = {Journal of Open Source Software},
	author = {VanderPlas, Jacob and Granger, Brian E. and Heer, Jeffrey and Moritz, Dominik and Wongsuphasawat, Kanit and Satyanarayan, Arvind and Lees, Eitan and Timofeev, Ilia and Welsh, Ben and Sievert, Scott},
	month = dec,
	year = {2018},
	pages = {1057},
	file = {Full Text PDF:/home/bo/Zotero/storage/IGZB7RMW/VanderPlas et al. - 2018 - Altair Interactive Statistical Visualizations for.pdf:application/pdf;Snapshot:/home/bo/Zotero/storage/E6EHAJHQ/joss.html:text/html},
}

@article{satyanarayan_vega-lite_2017,
	title = {Vega-{Lite}: {A} {Grammar} of {Interactive} {Graphics}},
	volume = {23},
	issn = {1077-2626},
	shorttitle = {Vega-{Lite}},
	url = {https://doi.org/10.1109/TVCG.2016.2599030},
	doi = {10.1109/TVCG.2016.2599030},
	abstract = {We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection.},
	number = {1},
	urldate = {2022-04-23},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Satyanarayan, Arvind and Moritz, Dominik and Wongsuphasawat, Kanit and Heer, Jeffrey},
	month = jan,
	year = {2017},
	pages = {341--350},
	file = {Submitted Version:/home/bo/Zotero/storage/3FKVXVY6/Satyanarayan et al. - 2017 - Vega-Lite A Grammar of Interactive Graphics.pdf:application/pdf},
}

@article{hsu_b-soid_2021,
	title = {B-{SOiD}, an open-source unsupervised algorithm for identification and fast prediction of behaviors},
	volume = {12},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-25420-x},
	doi = {10.1038/s41467-021-25420-x},
	abstract = {Abstract
            Studying naturalistic animal behavior remains a difficult objective. Recent machine learning advances have enabled limb localization; however, extracting behaviors requires ascertaining the spatiotemporal patterns of these positions. To provide a link from poses to actions and their kinematics, we developed B-SOiD - an open-source, unsupervised algorithm that identifies behavior without user bias. By training a machine classifier on pose pattern statistics clustered using new methods, our approach achieves greatly improved processing speed and the ability to generalize across subjects or labs. Using a frameshift alignment paradigm, B-SOiD overcomes previous temporal resolution barriers. Using only a single, off-the-shelf camera, B-SOiD provides categories of sub-action for trained behaviors and kinematic measures of individual limb trajectories in any animal model. These behavioral and kinematic measures are difficult but critical to obtain, particularly in the study of rodent and other models of pain, OCD, and movement disorders.},
	language = {en},
	number = {1},
	urldate = {2022-04-25},
	journal = {Nature Communications},
	author = {Hsu, Alexander I. and Yttri, Eric A.},
	month = dec,
	year = {2021},
	pages = {5188},
	file = {Hsu and Yttri - 2021 - B-SOiD, an open-source unsupervised algorithm for .pdf:/home/bo/Zotero/storage/7GJSQX4K/Hsu and Yttri - 2021 - B-SOiD, an open-source unsupervised algorithm for .pdf:application/pdf},
}

@article{daugman_uncertainty_1985,
	title = {Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two-dimensional visual cortical filters},
	volume = {2},
	copyright = {\&\#169; 1985 Optical Society of America},
	issn = {1520-8532},
	url = {https://opg.optica.org/josaa/abstract.cfm?uri=josaa-2-7-1160},
	doi = {10.1364/JOSAA.2.001160},
	abstract = {Two-dimensional spatial linear filters are constrained by general uncertainty relations that limit their attainable information resolution for orientation, spatial frequency, and two-dimensional (2D) spatial position. The theoretical lower limit for the joint entropy, or uncertainty, of these variables is achieved by an optimal 2D filter family whose spatial weighting functions are generated by exponentiated bivariate second-order polynomials with complex coefficients, the elliptic generalization of the one-dimensional elementary functions proposed in Gabor’s famous theory of communication [ J. Inst. Electr. Eng.93, 429 ( 1946)]. The set includes filters with various orientation bandwidths, spatial-frequency bandwidths, and spatial dimensions, favoring the extraction of various kinds of information from an image. Each such filter occupies an irreducible quantal volume (corresponding to an independent datum) in a four-dimensional information hyperspace whose axes are interpretable as 2D visual space, orientation, and spatial frequency, and thus such a filter set could subserve an optimally efficient sampling of these variables. Evidence is presented that the 2D receptive-field profiles of simple cells in mammalian visual cortex are well described by members of this optimal 2D filter family, and thus such visual neurons could be said to optimize the general uncertainty relations for joint 2D-spatial–2D-spectral information resolution. The variety of their receptive-field dimensions and orientation and spatial-frequency bandwidths, and the correlations among these, reveal several underlying constraints, particularly in width/length aspect ratio and principal axis organization, suggesting a polar division of labor in occupying the quantal volumes of information hyperspace. Such an ensemble of 2D neural receptive fields in visual cortex could locally embed coarse polar mappings of the orientation–frequency plane piecewise within the global retinotopic mapping of visual space, thus efficiently representing 2D spatial visual information by localized 2D spectral signatures.},
	language = {EN},
	number = {7},
	urldate = {2022-04-26},
	journal = {JOSA A},
	author = {Daugman, John G.},
	month = jul,
	year = {1985},
	note = {Publisher: Optica Publishing Group},
	pages = {1160--1169},
	file = {Snapshot:/home/bo/Zotero/storage/AWCERHFT/viewmedia.html:text/html},
}

@article{pereira_sleap_2022,
	title = {{SLEAP}: {A} deep learning system for multi-animal pose tracking},
	volume = {19},
	issn = {1548-7091, 1548-7105},
	shorttitle = {{SLEAP}},
	url = {https://www.nature.com/articles/s41592-022-01426-1},
	doi = {10.1038/s41592-022-01426-1},
	abstract = {Abstract
            The desire to understand how the brain generates and patterns behavior has driven rapid methodological innovation in tools to quantify natural animal behavior. While advances in deep learning and computer vision have enabled markerless pose estimation in individual animals, extending these to multiple animals presents unique challenges for studies of social behaviors or animals in their natural environments. Here we present Social LEAP Estimates Animal Poses (SLEAP), a machine learning system for multi-animal pose tracking. This system enables versatile workflows for data labeling, model training and inference on previously unseen data. SLEAP features an accessible graphical user interface, a standardized data model, a reproducible configuration system, over 30 model architectures, two approaches to part grouping and two approaches to identity tracking. We applied SLEAP to seven datasets across flies, bees, mice and gerbils to systematically evaluate each approach and architecture, and we compare it with other existing approaches. SLEAP achieves greater accuracy and speeds of more than 800 frames per second, with latencies of less than 3.5 ms at full 1,024 × 1,024 image resolution. This makes SLEAP usable for real-time applications, which we demonstrate by controlling the behavior of one animal on the basis of the tracking and detection of social interactions with another animal.},
	language = {en},
	number = {4},
	urldate = {2022-04-26},
	journal = {Nature Methods},
	author = {Pereira, Talmo D. and Tabris, Nathaniel and Matsliah, Arie and Turner, David M. and Li, Junyu and Ravindranath, Shruthi and Papadoyannis, Eleni S. and Normand, Edna and Deutsch, David S. and Wang, Z. Yan and McKenzie-Smith, Grace C. and Mitelut, Catalin C. and Castro, Marielisa Diez and D’Uva, John and Kislin, Mikhail and Sanes, Dan H. and Kocher, Sarah D. and Wang, Samuel S.-H. and Falkner, Annegret L. and Shaevitz, Joshua W. and Murthy, Mala},
	month = apr,
	year = {2022},
	pages = {486--495},
	file = {Pereira et al. - 2022 - SLEAP A deep learning system for multi-animal pos.pdf:/home/bo/Zotero/storage/EVEI95NE/Pereira et al. - 2022 - SLEAP A deep learning system for multi-animal pos.pdf:application/pdf},
}

@article{qiao_automated_2018,
	title = {Automated analysis of long-term grooming behavior in {Drosophila} using a k-nearest neighbors classifier},
	volume = {7},
	issn = {2050-084X},
	url = {https://elifesciences.org/articles/34497},
	doi = {10.7554/eLife.34497},
	abstract = {Despite being pervasive, the control of programmed grooming is poorly understood. We addressed this gap by developing a high-throughput platform that allows long-term detection of grooming in Drosophila melanogaster. In our method, a k-nearest neighbors algorithm automatically classifies fly behavior and finds grooming events with over 90\% accuracy in diverse genotypes. Our data show that flies spend {\textasciitilde}13\% of their waking time grooming, driven largely by two major internal programs. One of these programs regulates the timing of grooming and involves the core circadian clock components cycle, clock, and period. The second program regulates the duration of grooming and, while dependent on cycle and clock, appears to be independent of period. This emerging dual control model in which one program controls timing and another controls duration, resembles the two-process regulatory model of sleep. Together, our quantitative approach presents the opportunity for further dissection of mechanisms controlling long-term grooming in Drosophila.
          , 
            From birds that preen their feathers to dogs that lick their fur, many animals groom themselves. They do so to stay clean, but routine grooming also has a range of other uses, such as social communication or controlling body temperature. Despite its importance, grooming remains poorly understood; it is especially unclear how this behavior is regulated.
            Fruit flies could be a good model to study grooming because they are often used in laboratories to look into the genetic and brain mechanisms that control behavior. Flies clean themselves by sweeping their legs over their wings and body, but little is known about how the insects groom ‘naturally’ over long periods of time. This is partly because scientists have had to recognize and classify grooming behavior by eye, which is highly time-consuming.
            Here, Qiao, Li et al. have created a system to automatically detect grooming behavior in fruit flies over time. First, a camera records the movement of an individual insect. A computer then analyzes the images and picks out general features of the fly’s movement that can help work out what the insect is doing. For example, if a fly is moving its limbs, but not the main part of its body, it is probably grooming itself. Qiao, Li et al. then borrowed an algorithm from an area of computer science known as ‘machine learning’ to teach the computer how to classify each fly’s behavior automatically.
            The new system successfully recognized grooming behavior in over 90\% of cases, and it revealed that fruit flies spend about 13\% of their waking life grooming. It also showed that grooming seems to be controlled by two potentially independent internal programs. One program is tied to the internal body clock of the fly, and regulates when the insect grooms during the day. The other commands how long the fly cleans itself, and balances the amount of time spent on grooming with other behaviors.
            Cleaning oneself is not just important for animals to stay disease-free: it also reflects the general health state of an individual. For example, a loss of grooming is associated with sickness, old age, and, in humans, with mental illness. If scientists can understand how grooming is controlled at the brain and molecular levels, this may give an insight into how these mechanisms relate to diseases. The system created by Qiao, Li et al. could help to make such studies possible.},
	language = {en},
	urldate = {2022-05-10},
	journal = {eLife},
	author = {Qiao, Bing and Li, Chiyuan and Allen, Victoria W and Shirasu-Hiza, Mimi and Syed, Sheyum},
	month = feb,
	year = {2018},
	pages = {e34497},
	file = {Qiao et al. - 2018 - Automated analysis of long-term grooming behavior .pdf:/home/bo/Zotero/storage/G38V9NZU/Qiao et al. - 2018 - Automated analysis of long-term grooming behavior .pdf:application/pdf},
}

@article{segalin_mouse_2021,
	title = {The {Mouse} {Action} {Recognition} {System} ({MARS}) software pipeline for automated analysis of social behaviors in mice},
	volume = {10},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.63720},
	doi = {10.7554/eLife.63720},
	abstract = {The study of naturalistic social behavior requires quantification of animals’ interactions. This is generally done through manual annotation—a highly time-consuming and tedious process. Recent advances in computer vision enable tracking the pose (posture) of freely behaving animals. However, automatically and accurately classifying complex social behaviors remains technically challenging. We introduce the Mouse Action Recognition System (MARS), an automated pipeline for pose estimation and behavior quantification in pairs of freely interacting mice. We compare MARS’s annotations to human annotations and find that MARS’s pose estimation and behavior classification achieve human-level performance. We also release the pose and annotation datasets used to train MARS to serve as community benchmarks and resources. Finally, we introduce the Behavior Ensemble and Neural Trajectory Observatory (BENTO), a graphical user interface for analysis of multimodal neuroscience datasets. Together, MARS and BENTO provide an end-to-end pipeline for behavior data extraction and analysis in a package that is user-friendly and easily modifiable.},
	urldate = {2022-05-22},
	journal = {eLife},
	author = {Segalin, Cristina and Williams, Jalani and Karigo, Tomomi and Hui, May and Zelikowsky, Moriel and Sun, Jennifer J and Perona, Pietro and Anderson, David J and Kennedy, Ann},
	editor = {Berman, Gordon J and Wassum, Kate M and Gal, Asaf},
	month = nov,
	year = {2021},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {computer vision, machine learning, microendoscopic imaging, pose estimation, social behavior, software},
	pages = {e63720},
	file = {Full Text PDF:/home/bo/Zotero/storage/4JRY6MLD/Segalin et al. - 2021 - The Mouse Action Recognition System (MARS) softwar.pdf:application/pdf},
}

@article{whiteway_partitioning_2021,
	title = {Partitioning variability in animal behavioral videos using semi-supervised variational autoencoders},
	volume = {17},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009439},
	doi = {10.1371/journal.pcbi.1009439},
	abstract = {Recent neuroscience studies demonstrate that a deeper understanding of brain function requires a deeper understanding of behavior. Detailed behavioral measurements are now often collected using video cameras, resulting in an increased need for computer vision algorithms that extract useful information from video data. Here we introduce a new video analysis tool that combines the output of supervised pose estimation algorithms (e.g. DeepLabCut) with unsupervised dimensionality reduction methods to produce interpretable, low-dimensional representations of behavioral videos that extract more information than pose estimates alone. We demonstrate this tool by extracting interpretable behavioral features from videos of three different head-fixed mouse preparations, as well as a freely moving mouse in an open field arena, and show how these interpretable features can facilitate downstream behavioral and neural analyses. We also show how the behavioral features produced by our model improve the precision and interpretation of these downstream analyses compared to using the outputs of either fully supervised or fully unsupervised methods alone.},
	language = {en},
	number = {9},
	urldate = {2022-05-22},
	journal = {PLOS Computational Biology},
	author = {Whiteway, Matthew R. and Biderman, Dan and Friedman, Yoni and Dipoppa, Mario and Buchanan, E. Kelly and Wu, Anqi and Zhou, John and Bonacchi, Niccolò and Miska, Nathaniel J. and Noel, Jean-Paul and Rodriguez, Erica and Schartner, Michael and Socha, Karolina and Urai, Anne E. and Salzman, C. Daniel and Laboratory, The International Brain and Cunningham, John P. and Paninski, Liam},
	month = sep,
	year = {2021},
	note = {Publisher: Public Library of Science},
	keywords = {Neural networks, Animal behavior, Behavior, Equipment, Eye movements, Jaw, Medical facies, Mice},
	pages = {e1009439},
	file = {Full Text PDF:/home/bo/Zotero/storage/7FQG4QAP/Whiteway et al. - 2021 - Partitioning variability in animal behavioral vide.pdf:application/pdf},
}

@article{wu_neural_2021,
	title = {Neural control of affiliative touch in prosocial interaction},
	volume = {599},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03962-w},
	doi = {10.1038/s41586-021-03962-w},
	language = {en},
	number = {7884},
	urldate = {2022-05-22},
	journal = {Nature},
	author = {Wu, Ye Emily and Dang, James and Kingsbury, Lyle and Zhang, Mingmin and Sun, Fangmiao and Hu, Rongfeng K. and Hong, Weizhe},
	month = nov,
	year = {2021},
	pages = {262--267},
	file = {Wu et al. - 2021 - Neural control of affiliative touch in prosocial i.pdf:/home/bo/Zotero/storage/DLSTZEBX/Wu et al. - 2021 - Neural control of affiliative touch in prosocial i.pdf:application/pdf},
}

@article{bohnslav_deepethogram_2021,
	title = {{DeepEthogram}, a machine learning pipeline for supervised behavior classification from raw pixels},
	volume = {10},
	issn = {2050-084X},
	url = {https://elifesciences.org/articles/63377},
	doi = {10.7554/eLife.63377},
	abstract = {Videos of animal behavior are used to quantify researcher-­defined behaviors of interest to study neural function, gene mutations, and pharmacological therapies. Behaviors of interest are often scored manually, which is time-­consuming, limited to few behaviors, and variable across researchers. We created DeepEthogram: software that uses supervised machine learning to convert raw video pixels into an ethogram, the behaviors of interest present in each video frame. DeepEthogram is designed to be general-p­ urpose and applicable across species, behaviors, and video-­ recording hardware. It uses convolutional neural networks to compute motion, extract features from motion and images, and classify features into behaviors. Behaviors are classified with above 90\% accuracy on single frames in videos of mice and flies, matching expert-l­evel human performance. DeepEthogram accurately predicts rare behaviors, requires little training data, and generalizes across subjects. A graphical interface allows beginning-t­o-e­ nd analysis without end-u­ ser programming. DeepEthogram’s rapid, automatic, and reproducible labeling of researcher-­defined behaviors of interest may accelerate and enhance supervised behavior analysis. Code is available at: https:// github.com/jbohnslav/deepethogram.},
	language = {en},
	urldate = {2022-05-22},
	journal = {eLife},
	author = {Bohnslav, James P and Wimalasena, Nivanthika K and Clausing, Kelsey J and Dai, Yu Y and Yarmolinsky, David A and Cruz, Tomás and Kashlan, Adam D and Chiappe, M Eugenia and Orefice, Lauren L and Woolf, Clifford J and Harvey, Christopher D},
	month = sep,
	year = {2021},
	pages = {e63377},
	file = {Bohnslav et al. - 2021 - DeepEthogram, a machine learning pipeline for supe.pdf:/home/bo/Zotero/storage/QPVI42AX/Bohnslav et al. - 2021 - DeepEthogram, a machine learning pipeline for supe.pdf:application/pdf},
}

@article{deangelis_manifold_2019,
	title = {The manifold structure of limb coordination in walking {Drosophila}},
	volume = {8},
	issn = {2050-084X},
	url = {https://elifesciences.org/articles/46409},
	doi = {10.7554/eLife.46409},
	abstract = {Terrestrial locomotion requires animals to coordinate their limb movements to efficiently traverse their environment. While previous studies in hexapods have reported that limb coordination patterns can vary substantially, the structure of this variability is not yet well understood. Here, we characterized the symmetric and asymmetric components of variation in walking kinematics in the genetic model organism Drosophila. We found that Drosophila use a single continuum of coordination patterns without evidence for preferred configurations.},
	language = {en},
	urldate = {2022-05-22},
	journal = {eLife},
	author = {DeAngelis, Brian D and Zavatone-Veth, Jacob A and Clark, Damon A},
	month = jun,
	year = {2019},
	pages = {e46409},
	file = {DeAngelis et al. - 2019 - The manifold structure of limb coordination in wal.pdf:/home/bo/Zotero/storage/A4IYMWUE/DeAngelis et al. - 2019 - The manifold structure of limb coordination in wal.pdf:application/pdf},
}

@techreport{nilsson_simple_2020,
	type = {preprint},
	title = {Simple {Behavioral} {Analysis} ({SimBA}) – an open source toolkit for computer classification of complex social behaviors in experimental animals},
	url = {http://biorxiv.org/lookup/doi/10.1101/2020.04.19.049452},
	abstract = {Aberrant social behavior is a core feature of many neuropsychiatric disorders, yet the study of complex social behavior in freely moving rodents is relatively infrequently incorporated into preclinical models. This likely contributes to limited translational impact. A major bottleneck for the adoption of socially complex, ethology-rich, preclinical procedures are the technical limitations for consistently annotating detailed behavioral repertoires of rodent social behavior. Manual annotation is subjective, prone to observer drift, and extremely time-intensive. Commercial approaches are expensive and inferior to manual annotation. Open-source alternatives often require significant investments in specialized hardware and significant computational and programming knowledge. By combining recent computational advances in convolutional neural networks and pose-estimation with further machine learning analysis, complex rodent social behavior is primed for inclusion under the umbrella of computational neuroethology.},
	language = {en},
	urldate = {2022-05-22},
	institution = {Animal Behavior and Cognition},
	author = {Nilsson, Simon RO and Goodwin, Nastacia L. and Choong, Jia Jie and Hwang, Sophia and Wright, Hayden R and Norville, Zane C and Tong, Xiaoyu and Lin, Dayu and Bentzley, Brandon S. and Eshel, Neir and McLaughlin, Ryan J and Golden, Sam A.},
	month = apr,
	year = {2020},
	doi = {10.1101/2020.04.19.049452},
	file = {Nilsson et al. - 2020 - Simple Behavioral Analysis (SimBA) – an open sourc.pdf:/home/bo/Zotero/storage/VR94WFCF/Nilsson et al. - 2020 - Simple Behavioral Analysis (SimBA) – an open sourc.pdf:application/pdf},
}

@article{sainburg_parametric_2021,
	title = {Parametric {UMAP} {Embeddings} for {Representation} and {Semisupervised} {Learning}},
	volume = {33},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco_a_01434},
	doi = {10.1162/neco_a_01434},
	abstract = {UMAP is a nonparametric graph-based dimensionality reduction algorithm using applied Riemannian geometry and algebraic topology to find low-dimensional embeddings of structured data. The UMAP algorithm consists of two steps: (1) computing a graphical representation of a data set (fuzzy simplicial complex) and (2) through stochastic gradient descent, optimizing a low-dimensional embedding of the graph. Here, we extend the second step of UMAP to a parametric optimization over neural network weights, learning a parametric relationship between data and embedding. We first demonstrate that parametric UMAP performs comparably to its nonparametric counterpart while conferring the benefit of a learned parametric mapping (e.g., fast online embeddings for new data). We then explore UMAP as a regularization, constraining the latent distribution of autoencoders, parametrically varying global structure preservation, and improving classifier accuracy for semisupervised learning by capturing structure in unlabeled data.1},
	number = {11},
	urldate = {2022-05-31},
	journal = {Neural Computation},
	author = {Sainburg, Tim and McInnes, Leland and Gentner, Timothy Q.},
	month = oct,
	year = {2021},
	pages = {2881--2907},
	file = {Full Text PDF:/home/bo/Zotero/storage/MZ7VVKGA/Sainburg et al. - 2021 - Parametric UMAP Embeddings for Representation and .pdf:application/pdf},
}

@article{rauch_maximum_1965,
	title = {Maximum likelihood estimates of linear dynamic systems},
	volume = {3},
	issn = {0001-1452},
	url = {https://ui.adsabs.harvard.edu/abs/1965AIAAJ...3.1445R/abstract},
	doi = {10.2514/3.3166},
	language = {en},
	number = {8},
	urldate = {2022-06-09},
	journal = {AIAA Journal},
	author = {Rauch, H. E. and Striebel, C. T. and Tung, F.},
	month = aug,
	year = {1965},
	pages = {1445--1450},
	file = {Snapshot:/home/bo/Zotero/storage/B9D5XVJX/1965AIAAJ...3.html:text/html},
}

@article{brown_dictionary_2013,
	title = {A dictionary of behavioral motifs reveals clusters of genes affecting {Caenorhabditis} elegans locomotion},
	volume = {110},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.1211447110},
	doi = {10.1073/pnas.1211447110},
	number = {2},
	urldate = {2022-06-14},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Brown, André E. X. and Yemini, Eviatar I. and Grundy, Laura J. and Jucikas, Tadas and Schafer, William R.},
	month = jan,
	year = {2013},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {791--796},
	file = {Full Text PDF:/home/bo/Zotero/storage/KKI3ZUN3/Brown et al. - 2013 - A dictionary of behavioral motifs reveals clusters.pdf:application/pdf},
}

@article{ye_time_2011,
	title = {Time series shapelets: a novel technique that allows accurate, interpretable and fast classification},
	volume = {22},
	issn = {1573-756X},
	shorttitle = {Time series shapelets},
	url = {https://doi.org/10.1007/s10618-010-0179-5},
	doi = {10.1007/s10618-010-0179-5},
	abstract = {Classification of time series has been attracting great interest over the past decade. While dozens of techniques have been introduced, recent empirical evidence has strongly suggested that the simple nearest neighbor algorithm is very difficult to beat for most time series problems, especially for large-scale datasets. While this may be considered good news, given the simplicity of implementing the nearest neighbor algorithm, there are some negative consequences of this. First, the nearest neighbor algorithm requires storing and searching the entire dataset, resulting in a high time and space complexity that limits its applicability, especially on resource-limited sensors. Second, beyond mere classification accuracy, we often wish to gain some insight into the data and to make the classification result more explainable, which global characteristics of the nearest neighbor cannot provide. In this work we introduce a new time series primitive, time series shapelets, which addresses these limitations. Informally, shapelets are time series subsequences which are in some sense maximally representative of a class. We can use the distance to the shapelet, rather than the distance to the nearest neighbor to classify objects. As we shall show with extensive empirical evaluations in diverse domains, classification algorithms based on the time series shapelet primitives can be interpretable, more accurate, and significantly faster than state-of-the-art classifiers.},
	language = {en},
	number = {1},
	urldate = {2022-06-14},
	journal = {Data Mining and Knowledge Discovery},
	author = {Ye, Lexiang and Keogh, Eamonn},
	month = jan,
	year = {2011},
	keywords = {Data mining, Classification, Decision tree, Time series},
	pages = {149--182},
	file = {Full Text PDF:/home/bo/Zotero/storage/5Q6NG3AJ/Ye and Keogh - 2011 - Time series shapelets a novel technique that allo.pdf:application/pdf},
}

@article{bentley_multidimensional_1975,
	title = {Multidimensional binary search trees used for associative searching},
	volume = {18},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/361002.361007},
	doi = {10.1145/361002.361007},
	abstract = {This paper develops the multidimensional binary search tree (or k-d tree, where k is the dimensionality of the search space) as a data structure for storage of information to be retrieved by associative searches. The k-d tree is defined and examples are given. It is shown to be quite efficient in its storage requirements. A significant advantage of this structure is that a single data structure can handle many types of queries very efficiently. Various utility algorithms are developed; their proven average running times in an n record file are: insertion, O(log n); deletion of the root, O(n(k-1)/k); deletion of a random node, O(log n); and optimization (guarantees logarithmic performance of searches), O(n log n). Search algorithms are given for partial match queries with t keys specified [proven maximum running time of O(n(k-t)/k)] and for nearest neighbor queries [empirically observed average running time of O(log n).] These performances far surpass the best currently known algorithms for these tasks. An algorithm is presented to handle any general intersection query. The main focus of this paper is theoretical. It is felt, however, that k-d trees could be quite useful in many applications, and examples of potential uses are given.},
	number = {9},
	urldate = {2022-06-14},
	journal = {Communications of the ACM},
	author = {Bentley, Jon Louis},
	month = sep,
	year = {1975},
	keywords = {associative retrieval, attribute, binary search trees, binary tree insertion, information retrieval system, intersection queries, key, nearest neighbor queries, partial match queries},
	pages = {509--517},
	file = {Full Text PDF:/home/bo/Zotero/storage/PGMZFJP3/Bentley - 1975 - Multidimensional binary search trees used for asso.pdf:application/pdf},
}

@article{geissmann_ethoscopes_2017,
	title = {Ethoscopes: {An} open platform for high-throughput ethomics},
	volume = {15},
	issn = {1545-7885},
	shorttitle = {Ethoscopes},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2003026},
	doi = {10.1371/journal.pbio.2003026},
	abstract = {Here, we present the use of ethoscopes, which are machines for high-throughput analysis of behavior in Drosophila and other animals. Ethoscopes provide a software and hardware solution that is reproducible and easily scalable. They perform, in real-time, tracking and profiling of behavior by using a supervised machine learning algorithm, are able to deliver behaviorally triggered stimuli to flies in a feedback-loop mode, and are highly customizable and open source. Ethoscopes can be built easily by using 3D printing technology and rely on Raspberry Pi microcomputers and Arduino boards to provide affordable and flexible hardware. All software and construction specifications are available at http://lab.gilest.ro/ethoscope.},
	language = {en},
	number = {10},
	urldate = {2022-06-14},
	journal = {PLOS Biology},
	author = {Geissmann, Quentin and Rodriguez, Luis Garcia and Beckwith, Esteban J. and French, Alice S. and Jamasb, Arian R. and Gilestro, Giorgio F.},
	month = oct,
	year = {2017},
	note = {Publisher: Public Library of Science},
	keywords = {Animal behavior, Behavior, 3D printing, Computer software, Drosophila melanogaster, Light emitting diodes, Sleep, Sleep deprivation},
	pages = {e2003026},
	file = {Full Text PDF:/home/bo/Zotero/storage/RZE4WA85/Geissmann et al. - 2017 - Ethoscopes An open platform for high-throughput e.pdf:application/pdf;Snapshot:/home/bo/Zotero/storage/MYSJAIY5/article.html:text/html},
}

@article{van_alphen_deep_2021,
	title = {A deep sleep stage in {Drosophila} with a functional role in waste clearance},
	volume = {7},
	url = {https://www.science.org/doi/10.1126/sciadv.abc2999},
	doi = {10.1126/sciadv.abc2999},
	number = {4},
	urldate = {2022-06-15},
	journal = {Science Advances},
	author = {van Alphen, Bart and Semenza, Evan R. and Yap, Melvyn and van Swinderen, Bruno and Allada, Ravi},
	month = jan,
	year = {2021},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eabc2999},
	file = {Full Text PDF:/home/bo/Zotero/storage/KXNUCPZM/van Alphen et al. - 2021 - A deep sleep stage in Drosophila with a functional.pdf:application/pdf},
}

@article{geissmann_most_2019,
	title = {Most sleep does not serve a vital function: {Evidence} from {Drosophila} melanogaster},
	volume = {5},
	shorttitle = {Most sleep does not serve a vital function},
	url = {https://www.science.org/doi/10.1126/sciadv.aau9253},
	doi = {10.1126/sciadv.aau9253},
	number = {2},
	urldate = {2022-06-15},
	journal = {Science Advances},
	author = {Geissmann, Quentin and Beckwith, Esteban J. and Gilestro, Giorgio F.},
	month = feb,
	year = {2019},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eaau9253},
	file = {Full Text PDF:/home/bo/Zotero/storage/JIISJXPG/Geissmann et al. - 2019 - Most sleep does not serve a vital function Eviden.pdf:application/pdf},
}

@article{maaten_visualizing_2008,
	title = {Visualizing {Data} using t-{SNE}},
	volume = {9},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v9/vandermaaten08a.html},
	abstract = {We present a new technique called "t-SNE" that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images ofobjects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are significantly better than those produced by the other techniques on almost all of the data sets.},
	number = {86},
	urldate = {2022-06-15},
	journal = {Journal of Machine Learning Research},
	author = {Maaten, Laurens van der and Hinton, Geoffrey},
	year = {2008},
	pages = {2579--2605},
	file = {Full Text PDF:/home/bo/Zotero/storage/9UZ8IIMX/Maaten and Hinton - 2008 - Visualizing Data using t-SNE.pdf:application/pdf},
}

@inproceedings{tang_visualizing_2016,
	address = {Republic and Canton of Geneva, CHE},
	series = {{WWW} '16},
	title = {Visualizing {Large}-scale and {High}-dimensional {Data}},
	isbn = {978-1-4503-4143-1},
	url = {https://doi.org/10.1145/2872427.2883041},
	doi = {10.1145/2872427.2883041},
	abstract = {We study the problem of visualizing large-scale and high-dimensional data in a low-dimensional (typically 2D or 3D) space. Much success has been reported recently by techniques that first compute a similarity structure of the data points and then project them into a low-dimensional space with the structure preserved. These two steps suffer from considerable computational costs, preventing the state-of-the-art methods such as the t-SNE from scaling to large-scale and high-dimensional data (e.g., millions of data points and hundreds of dimensions). We propose the LargeVis, a technique that first constructs an accurately approximated K-nearest neighbor graph from the data and then layouts the graph in the low-dimensional space. Comparing to t-SNE, LargeVis significantly reduces the computational cost of the graph construction step and employs a principled probabilistic model for the visualization step, the objective of which can be effectively optimized through asynchronous stochastic gradient descent with a linear time complexity. The whole procedure thus easily scales to millions of high-dimensional data points. Experimental results on real-world data sets demonstrate that the LargeVis outperforms the state-of-the-art methods in both efficiency and effectiveness. The hyper-parameters of LargeVis are also much more stable over different data sets.},
	urldate = {2022-06-15},
	booktitle = {Proceedings of the 25th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Tang, Jian and Liu, Jingzhou and Zhang, Ming and Mei, Qiaozhu},
	month = apr,
	year = {2016},
	keywords = {big data, high-dimensional data, visualization},
	pages = {287--297},
	file = {Full Text PDF:/home/bo/Zotero/storage/YA3LMF8X/Tang et al. - 2016 - Visualizing Large-scale and High-dimensional Data.pdf:application/pdf},
}

@article{tenenbaum_global_2000,
	title = {A {Global} {Geometric} {Framework} for {Nonlinear} {Dimensionality} {Reduction}},
	volume = {290},
	url = {https://www.science.org/doi/10.1126/science.290.5500.2319},
	doi = {10.1126/science.290.5500.2319},
	number = {5500},
	urldate = {2022-06-15},
	journal = {Science},
	author = {Tenenbaum, Joshua B. and Silva, Vin de and Langford, John C.},
	month = dec,
	year = {2000},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {2319--2323},
}

@article{belkin_laplacian_2003,
	title = {Laplacian {Eigenmaps} for {Dimensionality} {Reduction} and {Data} {Representation}},
	volume = {15},
	issn = {0899-7667},
	doi = {10.1162/089976603321780317},
	abstract = {One of the central problems in machine learning and pattern recognition is to develop appropriate representations for complex data. We consider the problem of constructing a representation for data lying on a low-dimensional manifold embedded in a high-dimensional space. Drawing on the correspondence between the graph Laplacian, the Laplace Beltrami operator on the manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for representing the high-dimensional data. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality-preserving properties and a natural connection to clustering. Some potential applications and illustrative examples are discussed.},
	number = {6},
	journal = {Neural Computation},
	author = {Belkin, Mikhail and Niyogi, Partha},
	month = jun,
	year = {2003},
	note = {Conference Name: Neural Computation},
	pages = {1373--1396},
	file = {IEEE Xplore Abstract Record:/home/bo/Zotero/storage/7B94ZP2X/6789755.html:text/html},
}

@article{kruskal_multidimensional_1964,
	title = {Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis},
	volume = {29},
	issn = {0033-3123, 1860-0980},
	url = {http://link.springer.com/10.1007/BF02289565},
	doi = {10.1007/BF02289565},
	language = {en},
	number = {1},
	urldate = {2022-06-16},
	journal = {Psychometrika},
	author = {Kruskal, J. B.},
	month = mar,
	year = {1964},
	pages = {1--27},
	file = {Kruskal - 1964 - Multidimensional scaling by optimizing goodness of.pdf:/home/bo/Zotero/storage/ILL4U39G/Kruskal - 1964 - Multidimensional scaling by optimizing goodness of.pdf:application/pdf},
}

@article{hotelling_analysis_1933,
	title = {Analysis of a complex of statistical variables into principal components},
	volume = {24},
	issn = {0022-0663},
	url = {https://search.ebscohost.com/login.aspx?direct=true&db=pdh&AN=1934-00645-001&site=eds-live},
	doi = {10.1037/h0071325},
	abstract = {The problem is stated in detail, a method of analysis is derived and its geometrical meaning shown, methods of solution are illustrated and certain derivative problems are discussed. (To be concluded in October issue.) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {6},
	urldate = {2022-06-16},
	journal = {Journal of Educational Psychology},
	author = {Hotelling, H.},
	month = sep,
	year = {1933},
	note = {Publisher: Warwick \& York},
	keywords = {Statistical Analysis, Statistical Variables, statistical analysis, statistical variables},
	pages = {417--441},
	file = {EBSCO Full Text:/home/bo/Zotero/storage/W8IUNC5W/Hotelling - 1933 - Analysis of a complex of statistical variables int.pdf:application/pdf},
}

@inproceedings{mikolov_distributed_2013,
	address = {Red Hook, NY, USA},
	series = {{NIPS}'13},
	title = {Distributed representations of words and phrases and their compositionality},
	abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
	urldate = {2022-06-16},
	booktitle = {Proceedings of the 26th {International} {Conference} on {Neural} {Information} {Processing} {Systems} - {Volume} 2},
	publisher = {Curran Associates Inc.},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = dec,
	year = {2013},
	pages = {3111--3119},
}

@misc{xiao_fashion-mnist_2017,
	title = {Fashion-{MNIST}: a {Novel} {Image} {Dataset} for {Benchmarking} {Machine} {Learning} {Algorithms}},
	shorttitle = {Fashion-{MNIST}},
	url = {http://arxiv.org/abs/1708.07747},
	doi = {10.48550/arXiv.1708.07747},
	abstract = {We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at https://github.com/zalandoresearch/fashion-mnist},
	urldate = {2022-06-16},
	publisher = {arXiv},
	author = {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
	month = sep,
	year = {2017},
	note = {Number: arXiv:1708.07747
arXiv:1708.07747 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Dataset is freely available at https://github.com/zalandoresearch/fashion-mnist Benchmark is available at http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/},
	file = {arXiv Fulltext PDF:/home/bo/Zotero/storage/IVW3GX4E/Xiao et al. - 2017 - Fashion-MNIST a Novel Image Dataset for Benchmark.pdf:application/pdf;arXiv.org Snapshot:/home/bo/Zotero/storage/W4ZYGH7Y/1708.html:text/html},
}

@techreport{nene_columbia_1996,
	type = {Technical {Report}},
	title = {Columbia {Object} {Image} {Library} ({COIL}-20)},
	url = {http://www.cs.columbia.edu/CAVE/software/softlib/coil-20.php},
	language = {en},
	number = {CUCS-005-96},
	institution = {Columbia University},
	author = {Nene, Sameer A and Nayar, Shree K and Murase, Hiroshi},
	month = feb,
	year = {1996},
	pages = {6},
	file = {Nene et al. - Columbia Object Image Library (COIL-20).pdf:/home/bo/Zotero/storage/EILHTCXU/Nene et al. - Columbia Object Image Library (COIL-20).pdf:application/pdf},
}

@article{hellinger_neue_1909,
	title = {Neue {Begründung} der {Theorie} quadratischer {Formen} von unendlichvielen {Veränderlichen}.},
	volume = {1909},
	issn = {1435-5345},
	url = {https://www.degruyter.com/document/doi/10.1515/crll.1909.136.210/html?lang=en},
	doi = {10.1515/crll.1909.136.210},
	abstract = {Article Neue Begründung der Theorie quadratischer Formen von unendlichvielen Veränderlichen. was published on July 1, 1909 in the journal Journal für die reine und angewandte Mathematik (volume 1909, issue 136).},
	language = {de},
	number = {136},
	urldate = {2022-06-16},
	journal = {Journal für die reine und angewandte Mathematik},
	author = {Hellinger, E.},
	month = jul,
	year = {1909},
	note = {Publisher: De Gruyter},
	pages = {210--271},
}

@inproceedings{dong_efficient_2011,
	address = {Hyderabad, India},
	title = {Efficient k-nearest neighbor graph construction for generic similarity measures},
	isbn = {978-1-4503-0632-4},
	url = {http://portal.acm.org/citation.cfm?doid=1963405.1963487},
	doi = {10.1145/1963405.1963487},
	abstract = {K-Nearest Neighbor Graph (K-NNG) construction is an important operation with many web related applications, including collaborative ﬁltering, similarity search, and many others in data mining and machine learning. Existing methods for K-NNG construction either do not scale, or are speciﬁc to certain similarity measures. We present NN-Descent, a simple yet eﬃcient algorithm for approximate K-NNG construction with arbitrary similarity measures. Our method is based on local search, has minimal space overhead and does not rely on any shared global index. Hence, it is especially suitable for large-scale applications where data structures need to be distributed over the network. We have shown with a variety of datasets and similarity measures that the proposed method typically converges to above 90\% recall with each point comparing only to several percent of the whole dataset on average.},
	language = {en},
	urldate = {2022-06-16},
	booktitle = {Proceedings of the 20th international conference on {World} wide web - {WWW} '11},
	publisher = {ACM Press},
	author = {Dong, Wei and Moses, Charikar and Li, Kai},
	year = {2011},
	pages = {577},
	file = {Dong et al. - 2011 - Efficient k-nearest neighbor graph construction fo.pdf:/home/bo/Zotero/storage/NLB5FN28/Dong et al. - 2011 - Efficient k-nearest neighbor graph construction fo.pdf:application/pdf},
}

@article{mcinnes_umap_2018,
	title = {{UMAP}: {Uniform} {Manifold} {Approximation} and {Projection}},
	volume = {3},
	issn = {2475-9066},
	shorttitle = {{UMAP}},
	url = {http://joss.theoj.org/papers/10.21105/joss.00861},
	doi = {10.21105/joss.00861},
	abstract = {Uniform Manifold Approximation and Projection (UMAP) is a dimension reduction technique that can be used for visualisation similarly to t-SNE, but also for general non-linear dimension reduction. UMAP has a rigorous mathematical foundation, but is simple to use, with a scikit-learn compatible API. UMAP is among the fastest manifold learning implementations available – significantly faster than most t-SNE implementations.},
	language = {en},
	number = {29},
	urldate = {2022-06-16},
	journal = {Journal of Open Source Software},
	author = {McInnes, Leland and Healy, John and Saul, Nathaniel and Großberger, Lukas},
	month = sep,
	year = {2018},
	pages = {861},
	file = {McInnes et al. - 2018 - UMAP Uniform Manifold Approximation and Projectio.pdf:/home/bo/Zotero/storage/GVUQY57E/McInnes et al. - 2018 - UMAP Uniform Manifold Approximation and Projectio.pdf:application/pdf},
}

@article{ali_timecluster_2019,
	title = {{TimeCluster}: dimension reduction applied to temporal data for visual analytics},
	volume = {35},
	issn = {0178-2789, 1432-2315},
	shorttitle = {{TimeCluster}},
	url = {http://link.springer.com/10.1007/s00371-019-01673-y},
	doi = {10.1007/s00371-019-01673-y},
	abstract = {There is a need for solutions which assist users to understand long time-series data by observing its changes over time, ﬁnding repeated patterns, detecting outliers, and effectively labeling data instances. Although these tasks are quite distinct and are usually tackled separately, we present an interactive visual analytics system and approach that can address these issues in a single system. It enables users to visualize, understand and explore univariate or multivariate long time-series data in one image using a connected scatter plot. It supports interactive analysis and exploration for pattern discovery and outlier detection. Different dimensionality reduction techniques are used and compared in our system. Because of its power of extracting features, deep learning is used for multivariate time-series along with 2D reduction techniques for rapid and easy interpretation and interaction with large amount of time-series data. We deploy our system with different time-series datasets and report two real-world case studies that are used to evaluate our system.},
	language = {en},
	number = {6-8},
	urldate = {2022-06-16},
	journal = {The Visual Computer},
	author = {Ali, Mohammed and Jones, Mark W. and Xie, Xianghua and Williams, Mark},
	month = jun,
	year = {2019},
	pages = {1013--1026},
	file = {Ali et al. - 2019 - TimeCluster dimension reduction applied to tempor.pdf:/home/bo/Zotero/storage/AAE87LEZ/Ali et al. - 2019 - TimeCluster dimension reduction applied to tempor.pdf:application/pdf},
}

@article{wiltschko_mapping_2015,
	title = {Mapping {Sub}-{Second} {Structure} in {Mouse} {Behavior}},
	volume = {88},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627315010375},
	doi = {10.1016/j.neuron.2015.11.031},
	abstract = {Complex animal behaviors are likely built from simpler modules, but their systematic identification in mammals remains a significant challenge. Here we use depth imaging to show that 3D mouse pose dynamics are structured at the sub-second timescale. Computational modeling of these fast dynamics effectively describes mouse behavior as a series of reused and stereotyped modules with defined transition probabilities. We demonstrate this combined 3D imaging and machine learning method can be used to unmask potential strategies employed by the brain to adapt to the environment, to capture both predicted and previously hidden phenotypes caused by genetic or neural manipulations, and to systematically expose the global structure of behavior within an experiment. This work reveals that mouse body language is built from identifiable components and is organized in a predictable fashion; deciphering this language establishes an objective framework for characterizing the influence of environmental cues, genes and neural activity on behavior.
Video Abstract},
	language = {en},
	number = {6},
	urldate = {2022-06-30},
	journal = {Neuron},
	author = {Wiltschko, Alexander B. and Johnson, Matthew J. and Iurilli, Giuliano and Peterson, Ralph E. and Katon, Jesse M. and Pashkovski, Stan L. and Abraira, Victoria E. and Adams, Ryan P. and Datta, Sandeep Robert},
	month = dec,
	year = {2015},
	pages = {1121--1135},
	file = {Full Text:/home/bo/Zotero/storage/XBRNXGJQ/Wiltschko et al. - 2015 - Mapping Sub-Second Structure in Mouse Behavior.pdf:application/pdf},
}

@article{breiman_random_2001,
	title = {Random {Forests}},
	volume = {45},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	language = {en},
	number = {1},
	urldate = {2022-07-18},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	month = oct,
	year = {2001},
	keywords = {classification, ensemble, regression},
	pages = {5--32},
	file = {Full Text PDF:/home/bo/Zotero/storage/VA2JW2VD/Breiman - 2001 - Random Forests.pdf:application/pdf},
}

@inproceedings{he_deep_2016,
	address = {Las Vegas, NV, USA},
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	isbn = {978-1-4673-8851-1},
	url = {http://ieeexplore.ieee.org/document/7780459/},
	doi = {10.1109/CVPR.2016.90},
	abstract = {Deeper neural networks are more difﬁcult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classiﬁcation task. We also present analysis on CIFAR-10 with 100 and 1000 layers.},
	language = {en},
	urldate = {2022-07-19},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = jun,
	year = {2016},
	pages = {770--778},
	file = {He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf:/home/bo/Zotero/storage/BFV6V5TP/He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf:application/pdf},
}

@article{pereira_quantifying_2020,
	title = {Quantifying behavior to understand the brain},
	volume = {23},
	language = {en},
	journal = {Nature Neuroscience},
	author = {Pereira, Talmo D},
	year = {2020},
	pages = {13},
	file = {Pereira - 2020 - Quantifying behavior to understand the brain.pdf:/home/bo/Zotero/storage/DVI8SN64/Pereira - 2020 - Quantifying behavior to understand the brain.pdf:application/pdf},
}

@article{anderson_toward_2014,
	title = {Toward a {Science} of {Computational} {Ethology}},
	volume = {84},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627314007934},
	doi = {10.1016/j.neuron.2014.09.005},
	abstract = {The new field of “Computational Ethology” is made possible by advances in technology, mathematics, and engineering that allow scientists to automate the measurement and the analysis of animal behavior. We explore the opportunities and long-term directions of research in this area.},
	language = {en},
	number = {1},
	urldate = {2022-07-20},
	journal = {Neuron},
	author = {Anderson, David J. and Perona, Pietro},
	month = oct,
	year = {2014},
	pages = {18--31},
	file = {Full Text:/home/bo/Zotero/storage/KISRFVK7/Anderson and Perona - 2014 - Toward a Science of Computational Ethology.pdf:application/pdf;ScienceDirect Snapshot:/home/bo/Zotero/storage/STHS39AQ/S0896627314007934.html:text/html},
}

@article{datta_computational_2019,
	title = {Computational {Neuroethology}: {A} {Call} to {Action}},
	volume = {104},
	issn = {0896-6273},
	shorttitle = {Computational {Neuroethology}},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627319308414},
	doi = {10.1016/j.neuron.2019.09.038},
	abstract = {The brain is worthy of study because it is in charge of behavior. A flurry of recent technical advances in measuring and quantifying naturalistic behaviors provide an important opportunity for advancing brain science. However, the problem of understanding unrestrained behavior in the context of neural recordings and manipulations remains unsolved, and developing approaches to addressing this challenge is critical. Here we discuss considerations in computational neuroethology—the science of quantifying naturalistic behaviors for understanding the brain—and propose strategies to evaluate progress. We point to open questions that require resolution and call upon the broader systems neuroscience community to further develop and leverage measures of naturalistic, unrestrained behavior, which will enable us to more effectively probe the richness and complexity of the brain.},
	language = {en},
	number = {1},
	urldate = {2022-07-20},
	journal = {Neuron},
	author = {Datta, Sandeep Robert and Anderson, David J. and Branson, Kristin and Perona, Pietro and Leifer, Andrew},
	month = oct,
	year = {2019},
	pages = {11--24},
	file = {Full Text:/home/bo/Zotero/storage/TG3RFX65/Datta et al. - 2019 - Computational Neuroethology A Call to Action.pdf:application/pdf;ScienceDirect Snapshot:/home/bo/Zotero/storage/SNBVG8QU/S0896627319308414.html:text/html},
}

@article{marques_structure_2018,
	title = {Structure of the {Zebrafish} {Locomotor} {Repertoire} {Revealed} with {Unsupervised} {Behavioral} {Clustering}},
	volume = {28},
	issn = {1879-0445},
	doi = {10.1016/j.cub.2017.12.002},
	abstract = {An important concept in ethology is that complex behaviors can be constructed from a set of basic motor patterns. Identifying the set of patterns available to an animal is key to making quantitative descriptions of behavior that reflect the underlying motor system organization. We addressed these questions in zebrafish larvae, which swim in bouts that are naturally segmented in time. We developed a robust and general purpose clustering method (clusterdv) to ensure accurate identification of movement clusters and applied it to a dataset consisting of millions of swim bouts, captured at high temporal resolution from a comprehensive set of behavioral contexts. We identified a set of thirteen basic swimming patterns that are used flexibly in various combinations across different behavioral contexts and show that this classification can be used to dissect the sensorimotor transformations underlying larval social behavior and hunting. Furthermore, using the same approach at different levels in the behavioral hierarchy, we show that the set of swim bouts are themselves constructed from a basic set of tail movements and that bouts are executed in sequences specific to different behaviors.},
	language = {eng},
	number = {2},
	journal = {Current biology: CB},
	author = {Marques, João C. and Lackner, Simone and Félix, Rita and Orger, Michael B.},
	month = jan,
	year = {2018},
	pmid = {29307558},
	keywords = {Animals, behavior, behavioral motifs, cluster analysis, Cluster Analysis, clusterdv, locomotion, motor control, sequences, Swimming, unsupervised machine learning, visual behavior, zebrafish, Zebrafish},
	pages = {181--195.e5},
	file = {Full Text:/home/bo/Zotero/storage/7P2INUIF/Marques et al. - 2018 - Structure of the Zebrafish Locomotor Repertoire Re.pdf:application/pdf},
}

@article{mearns_deconstructing_2020,
	title = {Deconstructing {Hunting} {Behavior} {Reveals} a {Tightly} {Coupled} {Stimulus}-{Response} {Loop}},
	volume = {30},
	issn = {1879-0445},
	doi = {10.1016/j.cub.2019.11.022},
	abstract = {Animal behavior often forms sequences, built from simple stereotyped actions and shaped by environmental cues. A comprehensive characterization of the interplay between an animal's movements and its environment is necessary to understand the sensorimotor transformations performed by the brain. Here, we use unsupervised methods to study behavioral sequences in zebrafish larvae. We generate a map of swim bouts, revealing that fish modulate their tail movements along a continuum. During prey capture, larvae produce stereotyped sequences using a subset of bouts from a broader behavioral repertoire. These sequences exhibit low-order transition dynamics and immediately respond to changes in visual cues. Chaining of prey capture bouts is disrupted in visually impaired (lakritz and blumenkohl) mutants, and removing the prey stimulus during ongoing behavior in closed-loop virtual reality causes larvae to immediately abort the hunting sequence. These results suggest that the continuous integration of sensory information is necessary to structure the behavior. This stimulus-response loop serves to bring prey into the anterior dorsal visual field of the larvae. Fish then release a capture strike maneuver comprising a stereotyped jaw movement and tail movements fine-tuned to the distance of the prey. Fish with only one intact eye fail to correctly position the prey in the strike zone, but are able to produce the strike itself. Our analysis shows that short-term integration of binocular visual cues shapes the behavioral dynamics of hunting, thus uncovering the temporal organization of a goal-directed behavior in a vertebrate.},
	language = {eng},
	number = {1},
	journal = {Current biology: CB},
	author = {Mearns, Duncan S. and Donovan, Joseph C. and Fernandes, António M. and Semmelhack, Julia L. and Baier, Herwig},
	month = jan,
	year = {2020},
	pmid = {31866365},
	keywords = {Animals, behavioral sequences, ethology, Predatory Behavior, prey capture, Stereotyped Behavior, unsupervised machine learning, Visual Perception, zebrafish, Zebrafish},
	pages = {54--69.e9},
	file = {Full Text:/home/bo/Zotero/storage/YEY27R6G/Mearns et al. - 2020 - Deconstructing Hunting Behavior Reveals a Tightly .pdf:application/pdf},
}
