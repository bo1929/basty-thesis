\chapter{Experiment Outlining}

\section{Overview of Experiment Outlining}
Each experiment comprises sixteen hours of video recording spanning both awake and asleep epochs.
Since we are only interested in the behavioral repertoire exhibited during sleep, time intervals where the animal is dormant, namely the dormancy epochs, should be detected before proceeding with the behavior mapping stage.
We characterize dormancy epochs by lack of macro-activities, i.e., significant postural and locational changes, which can be qualified by displacement of the animal.
After detecting and excluding intervals of macro-activities, we end up with time points where the fly is dormant.
Yet, we need further process the dormancy epochs, as we are not interested in the time points where the fly is totally quiescent.
Our major focus is on the micro-activity bouts manifested during a dormancy epoch.
In order to detect those bouts, we should distinguish micro-activities exhibited during dormant epochs from macro-activities by quantifying them with a closer look at various body parts. We use term ``bouts'' and ``epochs'' respectively for micro-activities and macro-activities to reflect their difference in terms of duration. As discussed in Section~\ref{section:analyzing-behavioral-repertoire}, behaviors categorized in micro-activities are tends to have shorter durations, compared to macro-activities.

In this stage, our ultimate goal is to extract bouts of micro-activities exhibited during the dormancy state.
Extracted micro-activity bouts constitute the data points that are subject to behavior mapping.
There are several benefits of reducing the data points to this subset of dormancy and micro-activity, compared to using the entire experiment for behavior mapping.
Considering the high frame rate and long length of video recordings, computational requirements is an important concern in our pipeline.
Since roughly at least $90\%$ of the frames are either totally quiescent or macro-activities, e.g., walking, this approach has the benefit of reducing the computational requirements significantly.
Another critical point is that, quiescent, e.g., rest, frames contain only noise energy, and normalizing each frame amplifies me normalization amplifies this low-level noise energy, generating a uniform-like probability distribution for behavioral representation \citep{todd_systematic_2017}.
Eliminating totally quiescent frames without any micro-activity avoids this.
Also, as we are only interested in the behaviors exhibited during sleep, excluding macro-activity frames prevent domination of large number of frames with walking and macro-activities in the behavioral embedding space.

\NOTE{Overview of sections.}

\section{Quantifying Activities}
\subsection{Dormancy and Macro-activity Epochs}
When the fly is awake, many behaviors are manifested by featuring major postural change and displacement in different ways.
We categorize this type of behaviors under the umbrella term of macro-activity, and dormancy is defined as the lack of macro-activities, covering micro-activities.
One can characterize macro-activities without considering its sub-categories by using the velocities, i.e., gradient features.
In order to distinguish sub-categories of macro-activities, such as walking and rearing, more detailed and descriptive features are required.
However, in our case, computing a single scalar value to capture overall movement of the fly results in sufficient performance for detecting macro-activity epochs. We define this feature value by summing gradient features for all time scales as follows:
\begin{equation}
	v_t = \sum_{\tau \in \mathcal{T}_G}{\sum_{i=1}^{N_G}{\V{M}^\mu_{t,\tau,i}}},
\end{equation}
where resulting velocity-based feature vector is $\V{v}=\qmatrix{v_1, \cdots, v_T}$. Essentially, high and low values of $v_t$ indicate macro-activity and dormancy, respectively. Micro-activities can not be detected using such a straightforward and general value, and therefore, can not be distinguished from dormancy by using only this quantity.

\subsection{Micro-activity Bouts}

\begin{equation}
	u_{t,i} = \sum_{\sfrac{1}{f} \in \mathcal{T}_G}{\V{W}_{t,f,i}}
\end{equation}

\section{Detecting Activities}

\subsection{Unsupervised Approach}

\subsection{Weakly Supervised Approach}
