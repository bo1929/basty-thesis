\chapter{Results}

\section{Employing the Pipeline and  Evaluation}\label{section:employing-proposed-pipeline}
Total of 11 experiments (7 wild type sleep and 4 sleep deprived) and their annotations are split as 10 training experiments and 1 test experiment for all combinations.
We report results and evaluate each split and demonstrate varying performance for different splits.

Our pipeline starts with the feature extraction stage, where raw tracking data generated by DeepLabCut is used to generate meaningful behavioral representations.
Body parts used to extract features are proboscis, haltere, thorax, head (left and right), leg joints (left and right).
We use oriented pose vales for body parts with left and right counterparts, as described in the Section~\ref{section:oriented-pose-values}.
We set the low confidence score threshold to detect occluded body parts to $0.075$.
Moving median window size $\tau$ is $15$ frames, ($0.5$ seconds) and threshold $\tau$ set to $15$ microns. If the position of a body part exceeds the median of the window centered around it by $\tau$, it is marked as occluded, as described in Section~\ref{section:detecting-occlusions}
Linear interpolation is used for imputation of marked frames.
After that, firstly, a median filter of size $6$ frames, and then a boxcar filter of size $6$ frames is applied to reduce the tracking noise and smooth the signal, without smoothing behaviors exhibited by rapid movements.
Aligning different orientations and transforming the frames to be egocentric did not result in performance improvement in our case, hence, we continued without making frames egocentric.

Then, we computed snapshot features and gradient features as described in Section~\ref{section:spatiotemporal-fetaures}, and given in the Table~\ref{table:spatiotemporal-features}.
In order to generate postural dynamics, wavelet transformation is applied to snapshot features at $20$ different frequency channels dyadically spaced between $1$ Hz and $20$ Hz (see Equation~\ref{equation:dyadically-spaced-spectrum} for determining spectrum frequencies).
Then different timescales are normalized as given in Equation~\ref{equation:wavelet-normalization}.
After flattening and $\textnormal{L}_1$ frame normalization, we ended up with a $13 \times 20 = 260$ dimensional behavioral representation matrix $\V{\hat{W}}$.
Similarly for gradient features, moving mean values are computed for a single timescale which is $33$ milliseconds, resulting in $9 \times 1 = 9$ dimensional behavioral representation matrix $\V{\hat{M}}^\mu$, which is only used for experiment outlining and constructing $\Dormancy$ set.

\begin{table}[htb!]
	\begin{adjustbox}{width=1\textwidth}
		\begin{tabular}{c l l}
			\toprule
			                                         & \multicolumn{1}{c}{\textbf{Snapshot Features}} & \multicolumn{1}{c}{\textbf{Gradient Features}} \\
			\cmidrule(lr){2-2}\cmidrule(lr){3-3}
			\multirow{7}{*}{Distance between}        & haltere and origin                             & head and proboscis                             \\
			                                         & proboscis and origin                           & thorax and proboscis                           \\
			                                         & thorax and origin                              & thorax and origin                              \\
			                                         & head and proboscis                             &                                                \\
			                                         & haltere and thorax                             &                                                \\
			                                         & (average) leg joints and origin                &                                                \\
			                                         & (average) leg joints and thorax                &                                                \\
			\cmidrule(lr){2-2}\cmidrule(lr){3-3}
			\multirow{3}{*}{Cartesian components of} & haltere                                        & head                                           \\
			                                         & head                                           & proboscis                                      \\
			                                         & thorax                                         & thorax                                         \\
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption{Computed spatio-temporal features. \label{table:spatiotemporal-features}}
\end{table}

After constructing behavioral representation matrices, experiment outlining stage of our pipeline takes place.
Here reported recall scores are for the frame set $\MicroActivity$, and it is desired to achieve high recall scores, except for the ``quiescent and other'' category.
We evaluate both unsupervised and supervised approaches.

For unsupervised experiment outlining, the threshold $c$ is set to decision boundary $\lambda_1$ of two Gaussian components for construction of $\Dormancy$ set.
Similarly, thresholds $c_i$ for each $\V{u}_i$ value are the first decision boundaries of $3$ Gaussian components, sorted by their means.
Resulting detection performance is quite poor for switch-like behavior of haltere, since this behavior occurs very subtly and it is similar to quiescent frames.
8 out of 11 splits, has recall score less than $0.5$.
Also, recall scores for two of sleep deprived experiment splits (FlyF19SDs) is below $0.15$, which makes it impossible to proceed with a successful mapping.

In the supervised approach, a random forest of decision trees \citep{breiman_random_2001} is utilized with $10$ estimators, where the maximum depth of each tree is $5$ and the criterion is Gini impurity.
For grooming, recall is always greater than $0.97$, which implies that we do not lose insignificant amount of annotated frames.
Similarly, the recall score of feeding drops below $0.95$ only once.
For proboscis pumping, 6 out of 11 splits have recall score greater than $0.9$, and performance is relatively poor for two splits ($0.61$ and $0.56$ recall).
Again, haltere switch is the most challenging behavioral category, but recall is often greater than $0.75$ as opposed to unsupervised approach.
Considering its superior performance over unsupervised approach, we proceed to behavior mapping by employing supervised outlining.

\begin{figure}[t]
	\centering
	\begin{subfigure}[b]{0.495\linewidth}
		\centering\includegraphics[width=\linewidth]{figures/OutliningPerformance-Supervised.pdf}
		\caption{Supervised detection.}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[b]{0.495\linewidth}
		\centering\includegraphics[width=\linewidth]{figures/OutliningPerformance-Unsupervised.pdf}
		\caption{Unsupervised detection.}
	\end{subfigure}%
	\caption[Performance summary of experiment outlining and micro-activity detection.]{Performance summary of experiment outlining and micro-activity detection.
		Red line indicates the macro average of accuracy scores achieved for each split.
		High recall scores are desired for behavioral categories, as opposed to quiescent frames.
		Supervised and unsupervised detections are given respectively in the left subfigure and in the right subfigure.}
\end{figure}

\begin{figure}[htb!]
	\centering
	\begin{subfigure}[ht!]{0.495\linewidth}
		\centering\includegraphics[width=\linewidth]{figures/AUC_ROC-DActfiltered.pdf}
		\caption{AUC scores for $\MicroActivity$ set. \label{figure:AUC-ROC-Act}}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[ht!]{0.495\linewidth}
		\centering\includegraphics[width=\linewidth]{figures/AUC_ROC-DAnnfiltered.pdf}
		\caption{AUC scores for annotated frames. \label{figure:AUC-ROC-Ann}}
	\end{subfigure}%

	\begin{subfigure}[ht!]{0.95\linewidth}
		\centering\includegraphics[width=\linewidth]{figures/PRC_ROC-DActfiltered.pdf}
		\caption{ROC and precision-recall curves for frames detected as micro-activity. \label{figure:ROC-PRC-Act}}
	\end{subfigure}%

	\begin{subfigure}[ht!]{0.95\linewidth}
		\centering\includegraphics[width=\linewidth]{figures/PRC_ROC-DAnnfiltered.pdf}
		\caption{ROC and precision-recall curves for annotated frames. \label{figure:ROC-PRC-Ann}}
	\end{subfigure}%
	\caption[Performance summary of behavior mapping demonstrated using receiver operating characteristic curve, precision-recall curve, and area under curve scores.
	]{Performance summary of behavior mapping demonstrated using receiver operating characteristic curve, precision-recall curve, and area under curve scores.
		The red line indicates the macro average of AUC scores for each split.
		Weighted average of ROC and precision-recall curves computed by interpolation.
		Scores and curves for both frames estimated as micro-activity and annotated frames are given respectively in Figures~\ref{figure:AUC-ROC-Act}, ~\ref{figure:ROC-PRC-Act} and in Figures~\ref{figure:AUC-ROC-Ann}, ~\ref{figure:ROC-PRC-Ann}.}
\end{figure}

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\linewidth]{figures/BehavioralScoresDistributions_perBehavior.pdf}
	\caption[Distributions of behavioral score values of each behavioral category for all splits.]{Distributions of behavioral score values of each behavioral category for all splits.
		Each box-plot column demonstrates the behavioral score distributions of target behaviors for the corresponding annotation.}
\end{figure}

\begin{figure}[ht!]
	\centering
	\begin{subfigure}[h]{0.55\linewidth}
		\centering\includegraphics[width=\linewidth]{figures/BehavioralScores-RepertoireDifference.pdf}
		\caption{Behavioral score values.}
	\end{subfigure}%
	\centering
	\begin{subfigure}[h]{0.45\linewidth}
		\centering\includegraphics[width=\linewidth]{figures/Entropy-RepertoireDifference.pdf}
		\caption{Entropy values, red line is the mean.}
	\end{subfigure}%
	\caption[Histogram of entropy values and box-plot of the behavioral scores computed using one unannotated and two annotated experiments with varying behavioral repertoires.]{Histogram of entropy values and box-plot of behavioral scores computed using one unannotated and two annotated experiments with varying behavioral repertoires.
		Here behavioral repertoire of FlyF1-03082020 is predicted separately with two different annotated experiments, namely FlyF14-08172021 and FlyM13-08172021.
		Behavioral scores and entropy values are computed for the haltere switch behavior.
		The latter one lacks the haltere switch behavior, and as a result behavioral scores tend to have higher entropy.
		Results demonstrates ability of the proposed pipeline to detect and discover unseen unannotated behavioral categories using behavioral scores.}
\end{figure}

\section{Analyzing Behavioral Repertoire}\label{section:analyzing-behavioral-repertoire}

\begin{figure}[ht!]
	\centering
	\begin{subfigure}[ht!]{0.95\linewidth}
		\centering\includegraphics[width=\linewidth]{figures/Velocity-WT-1T.pdf}
		\caption{Wild type.}
	\end{subfigure}%

	\begin{subfigure}[ht!]{0.95\linewidth}
		\centering\includegraphics[width=\linewidth]{figures/Velocity-SD-1T.pdf}
		\caption{Sleep deprived.}
	\end{subfigure}%
	\caption[Overall displacement values over entire experiments.]{Overall displacement values over entire experiments.
		Displacement of the body reveals long dormancy and sleep epochs, and macro-activities.
		Displacement values are computed as described in Equation~\ref{equation:displacement}, and smoothed with a rolling mean of 1 minute window.}
\end{figure}

\begin{figure}[ht!]
	\centering\includegraphics[width=\linewidth]{figures/ActivityBinned-Ann-WT-5T.pdf}
	\caption[Binned temporal heatmap of activities.]{Binned temporal heatmap of activities.
		Each bin is $5$ minutes, corresponding to $900$ frames.
		Activity value is computed as the ratio of the number of annotated frames and total number of frames in that bin.}
\end{figure}

\begin{figure}[ht!]
	\centering
	\begin{subfigure}[ht!]{0.95\linewidth}
		\centering
		\includegraphics[width=\linewidth]{figures/FeatureDistributions_perBehavior-Ann.pdf}
		\caption{Summation of all frequency channels of behavioral representation value for each spatio-temporal feature.}
	\end{subfigure}%

	\centering
	\begin{subfigure}[ht!]{0.95\linewidth}
		\centering
		\includegraphics[width=\linewidth]{figures/BoutDurationDistributions-Ann.pdf}
		\caption{Kernel density estimations of bout durations for each behavioral category. Variance of bout durations within and across behavioral categories demonstrates the rich behavioral repertoire.}
	\end{subfigure}%

	\centering
	\begin{subfigure}[ht!]{0.95\linewidth}
		\centering
		\includegraphics[width=\linewidth]{figures/TimeSpent-perBehavior-Ann.pdf}
		\caption{Time spent with each behavioral category for all experiments.}
	\end{subfigure}%
	\caption{Summary of behavioral repertoires of different fly, demonstrated using both spatial and temporal characteristics.}
\end{figure}

\begin{figure}[ht!]
	\centering
	\begin{subfigure}[ht!]{0.975\linewidth}
		\centering\includegraphics[width=\linewidth]{figures/Heatmap_BehavioralUsage-Ann.pdf}
		\caption{Rate of behavioral visits during the sleep within each $0.05$ sleep percentage bin. Each row is normalized to sum up to $1$.}
	\end{subfigure}%

	\centering
	\begin{subfigure}[ht!]{0.975\linewidth}
		\centering\includegraphics[width=\linewidth]{figures/CumulativeLine_BehavioralUsage-Ann.pdf}
		\centering\includegraphics[width=\linewidth]{figures/MeanCumRofC_BehavioralUsage-Ann.pdf}
		\caption{Cumulative behavioral visits for each behavior, behaviors with less than 2 bouts are excluded.}
	\end{subfigure}%

	\caption[Demonstration of behavioral visits during the sleep.]{Demonstration of behavioral visits during the sleep.
		Ethograms of flies are aligned by dividing longest dormant epoch to $100$ bin, corresponding to the sleep percentages.
		Number of behavioral visits are normalized by the total number of bouts for each fly and behavioral category, separately.}

	% \centering
	% \begin{subfigure}[b]{0.45\linewidth}
	% 	\centering
	% 	\includegraphics[width=\linewidth]{figures/FractionTime-Microactivity.pdf}
	% 	\caption{Fraction of time spent with micro-activities in dormant epochs, comparing wild type experiments and sleep deprived experiments.}
	% \end{subfigure}%
\end{figure}
