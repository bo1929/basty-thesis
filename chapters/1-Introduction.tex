\setlength{\parindent}{0pt}
\chapter{Introduction}\label{chapter:introduction}
Sleep is an essential behavioral program conserved across the animal kingdom, in diverse species ranging from jellyfish to humans, whose function remains unknown \citep{campbell_animal_1984, nath_jellyfish_2017}.
In mammals, sleep consists of multiple stages marked by physiological changes, including reductions in muscle tone and distinct electrophysiological activity patterns in the brain \citep{corner_sleep_1977, sauer_dynamics_2003} In invertebrates, sleep has largely been studied as a unitary process and identified by bouts of consolidated immobility.
Thus, careful characterization of underlying changes in behavior and physiology is needed for understanding the functional role of the sleep, and characterizing distinct sleep stages in powerful genetic model systems such as \textit{Drosophila Melanogaster}.

Recent technical advances enabled automated quantification of behaviors, and this has opened up a new field of ``computational ethology'' \citep{anderson_toward_2014, datta_computational_2019}.
Particularly, the recent progress in deep learning lead to emergence of  methods for tracking animal motion, which provided the opportunity of studying naturalistic behavior at an unprecedented resolution \citep{pereira_quantifying_2020}.
Developments of pose estimation and tracking tools such as DeepLabCut \citep{mathis_deeplabcut_2018} and SLEAP \citep{pereira_fast_2019, pereira_sleap_2022} collecting spatio-temporal data about the animals possible.
However, this data only consists of coordinate values in two or three-dimensional spatial domain, depending on the employed tracking tool.
Quantification of rich and complex behavioral repertoires of the animals, considering its temporal structure and ambiguity, is a fundamentally difficult problem without a clear ground truth, as discussed in \citet{pereira_quantifying_2020}.

Because a static set of pose values are not sufficient to describe spatio-temporal complexities of behaviors, converting positional coordinates to meaningful spatio-temporal feature representations is an essential step for capturing time varying structure of behaviors.
The first step of many behavior mapping pipelines is generating hand-crafted features describing relative positions of body-parts, distances between body-parts, angles between body-parts, and how these values change over time, e.g., velocities and angular velocities \citep{kabra_jaaba_2013, hsu_b-soid_2021, marshall_continuous_2021, nilsson_simple_2020}.
Alternatively, there exists several studies which directly compute behavioral representations from videos by employing deep learning \citep{bohnslav_deepethogram_2021}, or advanced computer vision techniques \citep{berman_mapping_2014, wiltschko_mapping_2015}.
For both approaches, resulting behavioral representations are high-dimensional time series that  can  also be used to generate a spectrogram representation as in \citet{berman_mapping_2014, todd_systematic_2017, marshall_continuous_2021}.

A popular approach is projecting high-dimensional time series of behavioral representations into a low-dimensional behavioral embedding; using either autoencoders \citep{whiteway_partitioning_2021, graving_vae-sne_2020} or manifold learning techniques, such as t-SNE \citep{maaten_visualizing_2008}, Isomap \citep{tenenbaum_global_2000} and UMAP \citep{mcinnes_umap_2020} \citep{berman_mapping_2014, marshall_continuous_2021, hsu_b-soid_2021, deangelis_manifold_2019, mearns_deconstructing_2020}.
Having appropriate behavioral representations available, one can perform supervised learning, given user-provided examples of behavioral categories.
Various algorithms are used for the task of learning behaviors, such as SVM \citet{boser_training_1992} by \citet{hsu_b-soid_2021}, LSTM \citep{hochreiter_long_1997} by \citet{wu_neural_2021}, and random forest ensembles \citep{breiman_random_2001} by \citet{kabra_jaaba_2013} and \citet{nilsson_simple_2020}.
Alternatively, unsupervised approaches are useful for discovering repeatedly and stereotypically exhibited behaviors, as ``behavioral clusters'' with clustering \citep{berman_mapping_2014, todd_systematic_2017, marques_structure_2018, marshall_continuous_2021} or ``behavioral states'' with state space models \citep{wiltschko_mapping_2015}.
The advantage of benefiting unsupervised learning is to avoid annotator bias, annotation cost, and various shortcomings of depending on human definitions of behavior.

Neuroscientist studying sleep have mainly focused on locomotor-type behaviors exhibited at night \citep{wiggin_covert_2020, nath_jellyfish_2017}, and attempts to understand underlying sleep-stages by measuring the overall displacement, and quiescence.
For example, commercially available Drosophila Activity Monitor (DAMs, Inc., Waltham, Massachusetts) are used extensively to  study circadian rhythms and sleep \citep{pfeiffenberger_processing_2010, pfeiffenberger_locomotor_2010}.
Relatively advanced systems, such as Ethoscopes \citep{geissmann_ethoscopes_2017}, has also been developed in recent years.
Featuring supervised machine learning, Ethoscopes learns to detect not only walking activity but also micro-activities (for example, in-place movements such as grooming, egg laying), but without a fine-grained categorization of micro-activities to more specific behaviors \citep{geissmann_most_2019}.
Hinting the importance of analyzing rich behavioral repertoire exhibited during sleep, \citet{van_alphen_deep_2021}, analyzed the functional role of proboscis extension behavior, but without automatizing behavioral analysis proboscis extension behavior is quantified by manually scanning through the videos.
Ad-hoc solutions, specifically dedicated to a single or to a small subset of behaviors has also been introduced.
\citet{itskov_automated_2014} presents a method, which utilizes capacitive measurements, for automated quantification of feeding behavior.
\citet{qiao_automated_2018} develops a system, which includes hardware and a platform for video recordings, for automated analysis of long-term grooming behavior in \textit{Drosophila Melanogaster}.
Their algorithm maps fly activity onto a three-dimensional behavior space utilizes $k$-nearest neighbors classifier.
However, complete phenotyping of behavior repertoire of sleep, which we address in this work, is not attempted in the literature.

Challenges.

Our approach and contribution.

Outline.

\NOTE{
	\begin{itemize}
		\item Systematic exploration of unsupervised methods for mapping behavior: \citep{todd_systematic_2017}
		\item Predictability and hierarchy in \textit{{Drosophila}} behavior: \citep{berman_predictability_2016}
		\item The manifold structure of limb coordination in walking {Drosophila}: \citep{deangelis_manifold_2019}
		\item {{VAE}-{SNE}: a deep generative model for simultaneous dimensionality reduction and clustering}: \citep{graving_vae-sne_2020}
	\end{itemize}
}
\NOTE{
	\begin{itemize}
		\item Continuous {Whole}-{Body} {3D} {Kinematic} {Recordings} across the {Rodent} {Behavioral} {Repertoire} - {SI}: \citep{marshall_continuous_2021}
		\item Mapping {Sub}-{Second} {Structure} in {Mouse} {Behavior}: \citep{wiltschko_mapping_2015}
		\item Neural control of affiliative touch in prosocial interaction: \citep{wu_neural_2021}
		\item Partitioning variability in animal behavioral videos using semi-supervised variational autoencoders: \citep{whiteway_partitioning_2021}
		\item Structure of the {Zebrafish} {Locomotor} {Repertoire} {Revealed} with {Unsupervised} {Behavioral} {Clustering}: \citep{marques_structure_2018}
		\item A dictionary of behavioral motifs reveals clusters of genes affecting {Caenorhabditis} elegans locomotion: \citep{brown_dictionary_2013}
		\item Deconstructing {Hunting} {Behavior} {Reveals} a {Tightly} {Coupled} {Stimulus}-{Response} {Loop}: \citep{mearns_deconstructing_2020}
	\end{itemize}
}
\NOTE{
	\begin{itemize}
		\item The {Mouse} {Action} {Recognition} {System} ({MARS}) software pipeline for automated analysis of social behaviors in mice: \citep{segalin_mouse_2021}
		\item {DeepEthogram}, a machine learning pipeline for supervised behavior classification from raw pixels: \citep{bohnslav_deepethogram_2021}
		\item B-{SOiD}, an open-source unsupervised algorithm for identification and fast prediction of behaviors: \citep{hsu_b-soid_2021}
		\item {JAABA}: interactive machine learning for automatic annotation of animal behavior: \citep{kabra_jaaba_2013}
		\item Simple {Behavioral} {Analysis} ({SimBA}) â€“ an open source toolkit for computer classification of complex social behaviors in experimental animals: \citep{nilsson_simple_2020}
	\end{itemize}
}
