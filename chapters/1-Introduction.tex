\setlength{\parindent}{0pt}
\chapter{Introduction}\label{chapter:introduction}
Sleep is an essential behavioral program conserved across the animal kingdom, in diverse species ranging from jellyfish to humans, whose function remains unknown \citep{campbell_animal_1984, nath_jellyfish_2017}.
In mammals, sleep consists of multiple stages marked by physiological changes, including reductions in muscle tone and distinct electrophysiological activity patterns in the brain \citep{corner_sleep_1977, sauer_dynamics_2003} In invertebrates, sleep has largely been studied as a unitary process and identified by bouts of consolidated immobility.
Thus, careful characterization of underlying changes in behavior and physiology is needed for understanding the functional role of the sleep, and characterizing distinct sleep stages in powerful genetic model systems such as \textit{Drosophila Melanogaster}.

Recent technical advances enabled automated quantification of behaviors, and this has opened up a new field of ``computational ethology'' \citep{anderson_toward_2014, datta_computational_2019}.
Particularly, the recent progress in deep learning lead to emergence of  methods for tracking animal motion, which provided the opportunity of studying naturalistic behavior at an unprecedented resolution \citep{pereira_quantifying_2020}.
Developments of pose estimation and tracking tools such as DeepLabCut \citep{mathis_deeplabcut_2018} and SLEAP \citep{pereira_fast_2019, pereira_sleap_2022} collecting spatio-temporal data about the animals possible.
However, this data only consists of coordinate values in two or three-dimensional spatial domain, depending on the employed tracking tool.
Quantification of rich and complex behavioral repertoires of the animals, considering its temporal structure and ambiguity, is a fundamentally difficult problem without a clear ground truth, as discussed in \citet{pereira_quantifying_2020}.

Because a static set of pose values are not sufficient to describe spatio-temporal complexities of behaviors, converting positional coordinates to meaningful spatio-temporal feature representations is an essential step for capturing the time-varying structure of behaviors.
The first step of many behavior mapping pipelines is generating hand-crafted features describing relative positions of body parts, distances between body parts, angles between body parts, and how these values change over time, e.g., velocities and angular velocities \citep{kabra_jaaba_2013, hsu_b-soid_2021, marshall_continuous_2021, nilsson_simple_2020}.
Alternatively, there exist several studies which directly compute behavioral representations from videos by employing deep learning \citep{bohnslav_deepethogram_2021}, or advanced computer vision techniques \citep{berman_mapping_2014, wiltschko_mapping_2015}.
For both approaches, resulting behavioral representations are high-dimensional time series that can also be used to generate a spectrogram representation as in \citet{berman_mapping_2014, todd_systematic_2017, marshall_continuous_2021}.

A popular approach is projecting high-dimensional time series of behavioral representations into a low-dimensional behavioral embedding; using either autoencoders \citep{whiteway_partitioning_2021, graving_vae-sne_2020} or manifold learning techniques, such as t-SNE \citep{maaten_visualizing_2008}, Isomap \citep{tenenbaum_global_2000} and UMAP \citep{mcinnes_umap_2020} \citep{berman_mapping_2014, marshall_continuous_2021, hsu_b-soid_2021, deangelis_manifold_2019, mearns_deconstructing_2020}.
Having appropriate behavioral representations available, one can perform supervised learning, given user-provided examples of behavioral categories.
Various algorithms are used for the task of learning behaviors, such as SVM \citet{boser_training_1992} by \citet{hsu_b-soid_2021}, LSTM \citep{hochreiter_long_1997} by \citet{wu_neural_2021}, and random forest ensembles \citep{breiman_random_2001} by \citet{kabra_jaaba_2013} and \citet{nilsson_simple_2020}.
Alternatively, unsupervised approaches are useful for discovering repeatedly and stereotypically exhibited behaviors, as ``behavioral clusters'' with clustering \citep{berman_mapping_2014, todd_systematic_2017, marques_structure_2018, marshall_continuous_2021} or ``behavioral states'' with state space models \citep{wiltschko_mapping_2015}.
The advantage of benefiting from unsupervised learning is to avoid annotator bias, annotation cost, and various shortcomings of depending on human definitions of behavior.

Neuroscientists studying sleep have mainly focused on locomotor-type behaviors exhibited at night \citep{wiggin_covert_2020, nath_jellyfish_2017}, and attempts to understand underlying sleep stages by measuring the overall displacement, and quiescence.
For example, the commercially available Drosophila Activity Monitor (DAMs, Inc., Waltham, Massachusetts) is used extensively to study circadian rhythms and sleep \citep{pfeiffenberger_processing_2010, pfeiffenberger_locomotor_2010}.
Relatively advanced systems, such as Ethoscopes \citep{geissmann_ethoscopes_2017}, have also been developed in recent years.
Featuring supervised machine learning, Ethoscopes learns to detect not only walking activity but also micro-activities (for example, in-place movements such as grooming, and egg laying) but without a fine-grained categorization of micro-activities to more specific behaviors \citep{geissmann_most_2019}.
Hinting at the importance of analyzing rich behavioral repertoire exhibited during sleep, \citet{van_alphen_deep_2021}, analyzed the functional role of proboscis pumping behavior, but without automatizing behavioral analysis proboscis pumping behavior is quantified by manually scanning through the videos.
Ad-hoc solutions, specifically dedicated to a single or a small subset of behaviors have also been introduced.
For example, \citet{itskov_automated_2014} presents a method that utilizes capacitive measurements, for automated quantification of feeding behavior.
Another such ad-hoc solution is developed by \citet{qiao_automated_2018}, and achieves automated analysis of long-term grooming behavior in \textit{Drosophila Melanogaster}.
Their method, including hardware and a platform for video recordings, maps fly activity onto a three-dimensional behavior space and utilizes a $k$-nearest neighbors classifier.
However, detailed phenotyping of the behavioral repertoire of sleep, which we aim to achieve in this work, has not been addressed in the literature.

The inherent structure of sleep is mainly characterized by reduced muscle activity and long dormancy epochs.
Thus, observable behaviors are exhibited much more scarcely and rarely, compared to wakefulness.
Moreover, during sleep, the behavioral repertoire of fruit flies substantially consists of in-place behaviors rather than major postural and positional.
For instance, proboscis pumping is an in-place behavior, which is not necessarily accompanied by a positional or postural change in the rest of the body.
Another such example is the switch-like behavior of the haltere which is characterized by the haltere's positional change in the order of microns and eventuates rapidly within a second.
Therefore, our task of phenotyping sleep requires tackling behaviors defined by unobtrusive changes that sparsely occur during long sleep cycles.
Previously developed behavior mapping models are not designed with such behaviors in mind.
Their main focus has been on behaviors that feature major postural and positional changes, such as walking and wing waggle.

In this work, we develop \texttt{basty} (Automated \underline{B}ehavioral \underline{A}nalysis of A\underline{s}leep Frui\underline{t} Fl\underline{y}), a novel, end-to-end pipeline made public as a configurable, open source, and easy-to-use software package\footnote{\texttt{basty}, implemented in Python, is publicly available at \url{https://github.com/bo1929/basty}}.
\texttt{basty} directly operates on the output of the pose estimation tools, such as DeepLabCut \citep{mathis_deeplabcut_2018} and SLEAP \cite{pereira_sleap_2022}.
Unlike previous behavior mapping studies, we focus on behavioral repertoire exhibited during dormancy, i.e., in-place behaviors such as grooming, switch-like haltere movement, postural adjustments.
Similar to previous studies, our approach is start by computing meaningful behavioral representations.
To this end, \texttt{basty} offers an easily configurable and flexible framework, which includes a novel preprocessing step, extensive spatio-temporal feature computation and spectrogram generation.
Enabling analysis of sleep experiments and biological inference, \texttt{basty} allows detecting activities in long sleep experiments (14-16 hours).
Activity detection can be done both in an supervised manner and unsupervised manner by using Gaussian mixture model and random forest ensembles, respectively.
The proposed pipeline includes a novel supervised behavior mapping approach, which take advantage of semi-supervised dimensionality reduction and nearest neighbors analysis in a low dimensional behavioral space.

We evaluate our pipeline with a dataset of sleep deprivation and wild-type sleep experiments, focusing on five behavioral categories: grooming, feeding, proboscis pumping, haltere switch, and postural adjustments.
Notably, automated quantification of switch-like movement of haltere is achieved for the first time in this work.
Results show that our pipeline successfully maps behavioral categories, achieving an AUC score of 0.8 with limited supervision.
We also demonstrate that our approach enables detecting unobserved behaviors and differences in behavioral repertoires.
Furthermore, we present an analysis of the behavioral repertoire exhibited during sleep.
Our analysis reveals spatio-temporal characteristics of the behaviors and their temporal organization; in both wild-type sleep and sleep-deprived experiments.

The thesis is organized as follows:
\begin{itemize}
	\item In Chapter~\ref{chapter:expt-data-collection} section, we describe how the sleep experiments are conducted.
	      We present the technical details for the collection of fly video recordings, and pose estimation data.
	\item Feature extraction stage is described in the Chapter~\ref{chapter:feature-extraction} in detail.
	      This chapter includes preprocessing, computation of spatio-temporal features, and wavelet transformation and sliding window moving statistics for the generation dynamic postural features.
	\item In Chapter~\ref{chapter:activity-detection}, we explain our approach for quantifying activities, and extracting bouts of micro-activities observed during the sleep.
	\item We describe our approach for fine-grained categorization of the exhibited behaviors in Chapter~\ref{chapter:behavior-mapping}.
	      In particular, behavioral embedding generation is discussed in Section~\ref{section:behavioral-embeddings}, and we explain nearest neighbor analysis in Section~\ref{section:nearest-neighbors-classification}.
	\item Evaluation of the pipeline and configurations that we used in \texttt{basty} is given in the Chapter~\ref{chapter:results}.
	      We also analyze the behavioral repertoire of the asleep fruit fly in terms of spatio-temporal characteristics later in this chapter.
	\item We conclude our work and discuss future directions in Chapter~\ref{chapter:conclusion}.
\end{itemize}
